{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append('./')\n",
    "from utils import load_dataset\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x, test_x, val_x, train_y, test_y, val_y, x_mean, x_std = load_dataset()\n",
    "N = train_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot = tf.one_hot(train_y,depth=2)\n",
    "val_y_one_hot = tf.one_hot(val_y,depth=2)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate= 0.005)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('models/lr.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8694 - accuracy: 0.5638\n",
      "Epoch 00001: val_loss improved from inf to 0.63385, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.8694 - accuracy: 0.5638 - val_loss: 0.6338 - val_accuracy: 0.7100\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6806 - accuracy: 0.6637\n",
      "Epoch 00002: val_loss improved from 0.63385 to 0.55825, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6806 - accuracy: 0.6637 - val_loss: 0.5582 - val_accuracy: 0.7600\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6020 - accuracy: 0.6938\n",
      "Epoch 00003: val_loss improved from 0.55825 to 0.48969, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6020 - accuracy: 0.6938 - val_loss: 0.4897 - val_accuracy: 0.7800\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5416 - accuracy: 0.7312\n",
      "Epoch 00004: val_loss improved from 0.48969 to 0.43200, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5416 - accuracy: 0.7312 - val_loss: 0.4320 - val_accuracy: 0.8100\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4930 - accuracy: 0.7862\n",
      "Epoch 00005: val_loss improved from 0.43200 to 0.39453, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4930 - accuracy: 0.7862 - val_loss: 0.3945 - val_accuracy: 0.8400\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4636 - accuracy: 0.8313\n",
      "Epoch 00006: val_loss improved from 0.39453 to 0.37742, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.4636 - accuracy: 0.8313 - val_loss: 0.3774 - val_accuracy: 0.8700\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4430 - accuracy: 0.8512\n",
      "Epoch 00007: val_loss improved from 0.37742 to 0.36964, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.4430 - accuracy: 0.8512 - val_loss: 0.3696 - val_accuracy: 0.8800\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4140 - accuracy: 0.8600\n",
      "Epoch 00008: val_loss improved from 0.36964 to 0.36844, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4140 - accuracy: 0.8600 - val_loss: 0.3684 - val_accuracy: 0.8600\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3958 - accuracy: 0.8700\n",
      "Epoch 00009: val_loss did not improve from 0.36844\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3958 - accuracy: 0.8700 - val_loss: 0.3708 - val_accuracy: 0.8600\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3817 - accuracy: 0.8800\n",
      "Epoch 00010: val_loss did not improve from 0.36844\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.3817 - accuracy: 0.8800 - val_loss: 0.3731 - val_accuracy: 0.8600\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3686 - accuracy: 0.8863\n",
      "Epoch 00011: val_loss did not improve from 0.36844\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.3686 - accuracy: 0.8863 - val_loss: 0.3726 - val_accuracy: 0.8600\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3548 - accuracy: 0.8913\n",
      "Epoch 00012: val_loss did not improve from 0.36844\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3548 - accuracy: 0.8913 - val_loss: 0.3686 - val_accuracy: 0.8900\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3398 - accuracy: 0.8938\n",
      "Epoch 00013: val_loss improved from 0.36844 to 0.36200, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.3398 - accuracy: 0.8938 - val_loss: 0.3620 - val_accuracy: 0.8800\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3239 - accuracy: 0.9013\n",
      "Epoch 00014: val_loss improved from 0.36200 to 0.35470, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.3239 - accuracy: 0.9013 - val_loss: 0.3547 - val_accuracy: 0.8900\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3084 - accuracy: 0.9062\n",
      "Epoch 00015: val_loss improved from 0.35470 to 0.34796, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.3084 - accuracy: 0.9062 - val_loss: 0.3480 - val_accuracy: 0.8900\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2949 - accuracy: 0.9075\n",
      "Epoch 00016: val_loss improved from 0.34796 to 0.34218, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.2949 - accuracy: 0.9075 - val_loss: 0.3422 - val_accuracy: 0.9000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2844 - accuracy: 0.9112\n",
      "Epoch 00017: val_loss improved from 0.34218 to 0.33716, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.2844 - accuracy: 0.9112 - val_loss: 0.3372 - val_accuracy: 0.8900\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2722 - accuracy: 0.9162\n",
      "Epoch 00018: val_loss improved from 0.33716 to 0.33302, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.2722 - accuracy: 0.9162 - val_loss: 0.3330 - val_accuracy: 0.8800\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2601 - accuracy: 0.9175\n",
      "Epoch 00019: val_loss improved from 0.33302 to 0.33007, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2601 - accuracy: 0.9175 - val_loss: 0.3301 - val_accuracy: 0.8800\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2506 - accuracy: 0.9150\n",
      "Epoch 00020: val_loss improved from 0.33007 to 0.32837, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.2506 - accuracy: 0.9150 - val_loss: 0.3284 - val_accuracy: 0.8700\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.9162\n",
      "Epoch 00021: val_loss improved from 0.32837 to 0.32748, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2423 - accuracy: 0.9162 - val_loss: 0.3275 - val_accuracy: 0.8600\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2346 - accuracy: 0.9162\n",
      "Epoch 00022: val_loss improved from 0.32748 to 0.32657, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.2346 - accuracy: 0.9162 - val_loss: 0.3266 - val_accuracy: 0.8500\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2271 - accuracy: 0.9187\n",
      "Epoch 00023: val_loss improved from 0.32657 to 0.32501, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.2271 - accuracy: 0.9187 - val_loss: 0.3250 - val_accuracy: 0.8300\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2197 - accuracy: 0.9262\n",
      "Epoch 00024: val_loss improved from 0.32501 to 0.32275, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.2197 - accuracy: 0.9262 - val_loss: 0.3228 - val_accuracy: 0.8300\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2124 - accuracy: 0.9275\n",
      "Epoch 00025: val_loss improved from 0.32275 to 0.32023, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.2124 - accuracy: 0.9275 - val_loss: 0.3202 - val_accuracy: 0.8400\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2053 - accuracy: 0.9312\n",
      "Epoch 00026: val_loss improved from 0.32023 to 0.31807, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.2053 - accuracy: 0.9312 - val_loss: 0.3181 - val_accuracy: 0.8400\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 0.9375\n",
      "Epoch 00027: val_loss improved from 0.31807 to 0.31684, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.1990 - accuracy: 0.9375 - val_loss: 0.3168 - val_accuracy: 0.8400\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 0.1937 - accuracy: 0.9400\n",
      "Epoch 00028: val_loss did not improve from 0.31684\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1937 - accuracy: 0.9400 - val_loss: 0.3170 - val_accuracy: 0.8400\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1882 - accuracy: 0.9413\n",
      "Epoch 00029: val_loss did not improve from 0.31684\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1882 - accuracy: 0.9413 - val_loss: 0.3183 - val_accuracy: 0.8500\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1824 - accuracy: 0.9475\n",
      "Epoch 00030: val_loss did not improve from 0.31684\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1824 - accuracy: 0.9475 - val_loss: 0.3198 - val_accuracy: 0.8500\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.9513\n",
      "Epoch 00031: val_loss did not improve from 0.31684\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1775 - accuracy: 0.9513 - val_loss: 0.3205 - val_accuracy: 0.8400\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1731 - accuracy: 0.9575\n",
      "Epoch 00032: val_loss did not improve from 0.31684\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1731 - accuracy: 0.9575 - val_loss: 0.3196 - val_accuracy: 0.8300\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1688 - accuracy: 0.9625\n",
      "Epoch 00033: val_loss did not improve from 0.31684\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1688 - accuracy: 0.9625 - val_loss: 0.3169 - val_accuracy: 0.8500\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1645 - accuracy: 0.9625\n",
      "Epoch 00034: val_loss improved from 0.31684 to 0.31288, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1645 - accuracy: 0.9625 - val_loss: 0.3129 - val_accuracy: 0.8500\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1602 - accuracy: 0.9650\n",
      "Epoch 00035: val_loss improved from 0.31288 to 0.30845, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.1602 - accuracy: 0.9650 - val_loss: 0.3084 - val_accuracy: 0.8800\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1561 - accuracy: 0.9663\n",
      "Epoch 00036: val_loss improved from 0.30845 to 0.30442, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.1561 - accuracy: 0.9663 - val_loss: 0.3044 - val_accuracy: 0.8900\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1524 - accuracy: 0.9688\n",
      "Epoch 00037: val_loss improved from 0.30442 to 0.30139, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1524 - accuracy: 0.9688 - val_loss: 0.3014 - val_accuracy: 0.8900\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1491 - accuracy: 0.9712\n",
      "Epoch 00038: val_loss improved from 0.30139 to 0.29953, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1491 - accuracy: 0.9712 - val_loss: 0.2995 - val_accuracy: 0.8900\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.9725\n",
      "Epoch 00039: val_loss improved from 0.29953 to 0.29855, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1456 - accuracy: 0.9725 - val_loss: 0.2986 - val_accuracy: 0.8900\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9725\n",
      "Epoch 00040: val_loss improved from 0.29855 to 0.29801, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1423 - accuracy: 0.9725 - val_loss: 0.2980 - val_accuracy: 0.8900\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.9737\n",
      "Epoch 00041: val_loss improved from 0.29801 to 0.29755, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1393 - accuracy: 0.9737 - val_loss: 0.2976 - val_accuracy: 0.8900\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1365 - accuracy: 0.9737\n",
      "Epoch 00042: val_loss improved from 0.29755 to 0.29705, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.1365 - accuracy: 0.9737 - val_loss: 0.2970 - val_accuracy: 0.8900\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1338 - accuracy: 0.9775\n",
      "Epoch 00043: val_loss improved from 0.29705 to 0.29652, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.1338 - accuracy: 0.9775 - val_loss: 0.2965 - val_accuracy: 0.8900\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1311 - accuracy: 0.9787\n",
      "Epoch 00044: val_loss improved from 0.29652 to 0.29610, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1311 - accuracy: 0.9787 - val_loss: 0.2961 - val_accuracy: 0.8900\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.9787\n",
      "Epoch 00045: val_loss improved from 0.29610 to 0.29595, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.1284 - accuracy: 0.9787 - val_loss: 0.2960 - val_accuracy: 0.8900\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.9787\n",
      "Epoch 00046: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1259 - accuracy: 0.9787 - val_loss: 0.2962 - val_accuracy: 0.8900\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.9787\n",
      "Epoch 00047: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1235 - accuracy: 0.9787 - val_loss: 0.2968 - val_accuracy: 0.9100\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1213 - accuracy: 0.9787\n",
      "Epoch 00048: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1213 - accuracy: 0.9787 - val_loss: 0.2977 - val_accuracy: 0.9100\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9800\n",
      "Epoch 00049: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1190 - accuracy: 0.9800 - val_loss: 0.2987 - val_accuracy: 0.9100\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1168 - accuracy: 0.9800\n",
      "Epoch 00050: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1168 - accuracy: 0.9800 - val_loss: 0.2995 - val_accuracy: 0.9100\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 0.9812\n",
      "Epoch 00051: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.1147 - accuracy: 0.9812 - val_loss: 0.3000 - val_accuracy: 0.9100\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1128 - accuracy: 0.9825\n",
      "Epoch 00052: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.1128 - accuracy: 0.9825 - val_loss: 0.2999 - val_accuracy: 0.9000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9825\n",
      "Epoch 00053: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1108 - accuracy: 0.9825 - val_loss: 0.2995 - val_accuracy: 0.9000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.9825\n",
      "Epoch 00054: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1089 - accuracy: 0.9825 - val_loss: 0.2987 - val_accuracy: 0.9000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1070 - accuracy: 0.9837\n",
      "Epoch 00055: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.1070 - accuracy: 0.9837 - val_loss: 0.2978 - val_accuracy: 0.9000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.9850\n",
      "Epoch 00056: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1052 - accuracy: 0.9850 - val_loss: 0.2970 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.9850\n",
      "Epoch 00057: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1036 - accuracy: 0.9850 - val_loss: 0.2966 - val_accuracy: 0.8900\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1019 - accuracy: 0.9850\n",
      "Epoch 00058: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1019 - accuracy: 0.9850 - val_loss: 0.2965 - val_accuracy: 0.9000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 0.9850\n",
      "Epoch 00059: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1002 - accuracy: 0.9850 - val_loss: 0.2967 - val_accuracy: 0.9000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.9862\n",
      "Epoch 00060: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0987 - accuracy: 0.9862 - val_loss: 0.2971 - val_accuracy: 0.9000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9862\n",
      "Epoch 00061: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0972 - accuracy: 0.9862 - val_loss: 0.2975 - val_accuracy: 0.9000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.9862\n",
      "Epoch 00062: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0957 - accuracy: 0.9862 - val_loss: 0.2978 - val_accuracy: 0.8900\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.9862\n",
      "Epoch 00063: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0942 - accuracy: 0.9862 - val_loss: 0.2980 - val_accuracy: 0.8900\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.9862\n",
      "Epoch 00064: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0928 - accuracy: 0.9862 - val_loss: 0.2982 - val_accuracy: 0.8900\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.9862\n",
      "Epoch 00065: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0915 - accuracy: 0.9862 - val_loss: 0.2984 - val_accuracy: 0.8800\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.9875\n",
      "Epoch 00066: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0901 - accuracy: 0.9875 - val_loss: 0.2987 - val_accuracy: 0.8800\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.9875\n",
      "Epoch 00067: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0888 - accuracy: 0.9875 - val_loss: 0.2993 - val_accuracy: 0.8800\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0876 - accuracy: 0.9887\n",
      "Epoch 00068: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0876 - accuracy: 0.9887 - val_loss: 0.2999 - val_accuracy: 0.8800\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9887\n",
      "Epoch 00069: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0863 - accuracy: 0.9887 - val_loss: 0.3006 - val_accuracy: 0.8800\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.9887\n",
      "Epoch 00070: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0851 - accuracy: 0.9887 - val_loss: 0.3012 - val_accuracy: 0.8800\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9887\n",
      "Epoch 00071: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0839 - accuracy: 0.9887 - val_loss: 0.3016 - val_accuracy: 0.8800\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9900\n",
      "Epoch 00072: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0828 - accuracy: 0.9900 - val_loss: 0.3018 - val_accuracy: 0.8800\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 0.9900\n",
      "Epoch 00073: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0816 - accuracy: 0.9900 - val_loss: 0.3018 - val_accuracy: 0.8800\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.9912\n",
      "Epoch 00074: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0805 - accuracy: 0.9912 - val_loss: 0.3018 - val_accuracy: 0.8800\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9912\n",
      "Epoch 00075: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0795 - accuracy: 0.9912 - val_loss: 0.3017 - val_accuracy: 0.8800\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9912\n",
      "Epoch 00076: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0784 - accuracy: 0.9912 - val_loss: 0.3018 - val_accuracy: 0.8800\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9912\n",
      "Epoch 00077: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0774 - accuracy: 0.9912 - val_loss: 0.3020 - val_accuracy: 0.8800\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9912\n",
      "Epoch 00078: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0764 - accuracy: 0.9912 - val_loss: 0.3023 - val_accuracy: 0.8800\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9912\n",
      "Epoch 00079: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0754 - accuracy: 0.9912 - val_loss: 0.3026 - val_accuracy: 0.8800\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0744 - accuracy: 0.9937\n",
      "Epoch 00080: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0744 - accuracy: 0.9937 - val_loss: 0.3030 - val_accuracy: 0.8800\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9950\n",
      "Epoch 00081: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0735 - accuracy: 0.9950 - val_loss: 0.3033 - val_accuracy: 0.8800\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.9950\n",
      "Epoch 00082: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0726 - accuracy: 0.9950 - val_loss: 0.3035 - val_accuracy: 0.8800\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9950\n",
      "Epoch 00083: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0717 - accuracy: 0.9950 - val_loss: 0.3037 - val_accuracy: 0.8800\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9950\n",
      "Epoch 00084: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0708 - accuracy: 0.9950 - val_loss: 0.3038 - val_accuracy: 0.8800\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9975\n",
      "Epoch 00085: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0699 - accuracy: 0.9975 - val_loss: 0.3039 - val_accuracy: 0.8800\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9975\n",
      "Epoch 00086: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0691 - accuracy: 0.9975 - val_loss: 0.3041 - val_accuracy: 0.8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9975\n",
      "Epoch 00087: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0682 - accuracy: 0.9975 - val_loss: 0.3044 - val_accuracy: 0.8800\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9975\n",
      "Epoch 00088: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0674 - accuracy: 0.9975 - val_loss: 0.3048 - val_accuracy: 0.8800\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9975\n",
      "Epoch 00089: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0666 - accuracy: 0.9975 - val_loss: 0.3052 - val_accuracy: 0.8800\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9975\n",
      "Epoch 00090: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0658 - accuracy: 0.9975 - val_loss: 0.3055 - val_accuracy: 0.8800\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9975\n",
      "Epoch 00091: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0651 - accuracy: 0.9975 - val_loss: 0.3058 - val_accuracy: 0.8800\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.9975\n",
      "Epoch 00092: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0643 - accuracy: 0.9975 - val_loss: 0.3061 - val_accuracy: 0.8800\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0636 - accuracy: 0.9975\n",
      "Epoch 00093: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0636 - accuracy: 0.9975 - val_loss: 0.3062 - val_accuracy: 0.8800\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9975\n",
      "Epoch 00094: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0628 - accuracy: 0.9975 - val_loss: 0.3064 - val_accuracy: 0.8800\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9975\n",
      "Epoch 00095: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0621 - accuracy: 0.9975 - val_loss: 0.3065 - val_accuracy: 0.8700\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9975\n",
      "Epoch 00096: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0614 - accuracy: 0.9975 - val_loss: 0.3067 - val_accuracy: 0.8700\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9975\n",
      "Epoch 00097: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0607 - accuracy: 0.9975 - val_loss: 0.3069 - val_accuracy: 0.8700\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9987\n",
      "Epoch 00098: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0601 - accuracy: 0.9987 - val_loss: 0.3071 - val_accuracy: 0.8700\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9987\n",
      "Epoch 00099: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0594 - accuracy: 0.9987 - val_loss: 0.3073 - val_accuracy: 0.8700\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9987\n",
      "Epoch 00100: val_loss did not improve from 0.29595\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0587 - accuracy: 0.9987 - val_loss: 0.3076 - val_accuracy: 0.8700\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(32, 32)),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_x,y_one_hot, epochs=100,batch_size=N,verbose=1,\\\n",
    "          validation_data=(val_x,val_y_one_hot),callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.9987499713897705\n",
      "Validation accuracy:  0.8700000047683716\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# use the model to predict the test inputs\n",
    "predictions = model.predict(test_x)\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "print('Training accuracy: ', acc[-1])\n",
    "print('Validation accuracy: ', val_acc[-1])\n",
    "\n",
    "\n",
    "def index_of_max(output_list):\n",
    "    list_of_indicies = []\n",
    "    for sub_list in output_list:\n",
    "        list_of_indicies.append(np.argmax(sub_list))\n",
    "    return list_of_indicies\n",
    "\n",
    "confusion = tf.math.confusion_matrix(\n",
    "    labels=tf.constant(test_y.flatten()),\n",
    "    predictions=tf.constant(index_of_max(predictions)),\n",
    "    num_classes=2)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(confusion, xticklabels=['0','1'], yticklabels=['0','1'], \n",
    "            annot=True, fmt='g'),\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, val_x, train_y, test_y, val_y, x_mean, x_std = load_dataset()\n",
    "train_x = np.expand_dims(train_x,-1)\n",
    "test_x = np.expand_dims(test_x,-1)\n",
    "val_x = np.expand_dims(val_x,-1)\n",
    "\n",
    "print (train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_74 (Conv2D)           (None, 32, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 1,278,114\n",
      "Trainable params: 1,278,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_train_function.<locals>.train_function at 0x7f5ed422b4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6953 - accuracy: 0.5250WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5ef429def0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61091, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.6953 - accuracy: 0.5250 - val_loss: 0.6109 - val_accuracy: 0.8800\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6062 - accuracy: 0.8938\n",
      "Epoch 00002: val_loss improved from 0.61091 to 0.46932, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6062 - accuracy: 0.8938 - val_loss: 0.4693 - val_accuracy: 0.8800\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4579 - accuracy: 0.8950\n",
      "Epoch 00003: val_loss improved from 0.46932 to 0.37563, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.4579 - accuracy: 0.8950 - val_loss: 0.3756 - val_accuracy: 0.8800\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3531 - accuracy: 0.8988\n",
      "Epoch 00004: val_loss did not improve from 0.37563\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.3531 - accuracy: 0.8988 - val_loss: 0.4248 - val_accuracy: 0.8800\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.9000\n",
      "Epoch 00005: val_loss did not improve from 0.37563\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.3858 - accuracy: 0.9000 - val_loss: 0.4108 - val_accuracy: 0.8800\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3712 - accuracy: 0.9000\n",
      "Epoch 00006: val_loss improved from 0.37563 to 0.36497, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.3712 - accuracy: 0.9000 - val_loss: 0.3650 - val_accuracy: 0.8800\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3388 - accuracy: 0.9000\n",
      "Epoch 00007: val_loss improved from 0.36497 to 0.34578, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.3388 - accuracy: 0.9000 - val_loss: 0.3458 - val_accuracy: 0.8800\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3346 - accuracy: 0.9000\n",
      "Epoch 00008: val_loss improved from 0.34578 to 0.32691, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3346 - accuracy: 0.9000 - val_loss: 0.3269 - val_accuracy: 0.8800\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3115 - accuracy: 0.9000\n",
      "Epoch 00009: val_loss improved from 0.32691 to 0.32423, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3115 - accuracy: 0.9000 - val_loss: 0.3242 - val_accuracy: 0.8800\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3182 - accuracy: 0.9000\n",
      "Epoch 00010: val_loss improved from 0.32423 to 0.31894, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.3182 - accuracy: 0.9000 - val_loss: 0.3189 - val_accuracy: 0.8800\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3172 - accuracy: 0.9013\n",
      "Epoch 00011: val_loss improved from 0.31894 to 0.30635, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.3172 - accuracy: 0.9013 - val_loss: 0.3063 - val_accuracy: 0.8800\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3036 - accuracy: 0.9025\n",
      "Epoch 00012: val_loss improved from 0.30635 to 0.29220, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.3036 - accuracy: 0.9025 - val_loss: 0.2922 - val_accuracy: 0.8800\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2856 - accuracy: 0.9000\n",
      "Epoch 00013: val_loss improved from 0.29220 to 0.27658, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.2856 - accuracy: 0.9000 - val_loss: 0.2766 - val_accuracy: 0.8800\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.9000\n",
      "Epoch 00014: val_loss improved from 0.27658 to 0.25904, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2731 - accuracy: 0.9000 - val_loss: 0.2590 - val_accuracy: 0.8800\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2602 - accuracy: 0.9000\n",
      "Epoch 00015: val_loss improved from 0.25904 to 0.24614, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.2602 - accuracy: 0.9000 - val_loss: 0.2461 - val_accuracy: 0.8900\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 0.9087\n",
      "Epoch 00016: val_loss improved from 0.24614 to 0.22135, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.2588 - accuracy: 0.9087 - val_loss: 0.2213 - val_accuracy: 0.9100\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2337 - accuracy: 0.9125\n",
      "Epoch 00017: val_loss improved from 0.22135 to 0.20069, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.2337 - accuracy: 0.9125 - val_loss: 0.2007 - val_accuracy: 0.9000\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2268 - accuracy: 0.9125\n",
      "Epoch 00018: val_loss improved from 0.20069 to 0.18852, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2268 - accuracy: 0.9125 - val_loss: 0.1885 - val_accuracy: 0.9200\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2144 - accuracy: 0.9150\n",
      "Epoch 00019: val_loss improved from 0.18852 to 0.17161, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.2144 - accuracy: 0.9150 - val_loss: 0.1716 - val_accuracy: 0.9300\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1977 - accuracy: 0.9275\n",
      "Epoch 00020: val_loss improved from 0.17161 to 0.15026, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.1977 - accuracy: 0.9275 - val_loss: 0.1503 - val_accuracy: 0.9400\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1796 - accuracy: 0.9413\n",
      "Epoch 00021: val_loss improved from 0.15026 to 0.14044, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.1796 - accuracy: 0.9413 - val_loss: 0.1404 - val_accuracy: 0.9400\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1650 - accuracy: 0.9375\n",
      "Epoch 00022: val_loss improved from 0.14044 to 0.13098, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.1650 - accuracy: 0.9375 - val_loss: 0.1310 - val_accuracy: 0.9500\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.9500\n",
      "Epoch 00023: val_loss improved from 0.13098 to 0.11705, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.1503 - accuracy: 0.9500 - val_loss: 0.1171 - val_accuracy: 0.9400\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1447 - accuracy: 0.9513\n",
      "Epoch 00024: val_loss improved from 0.11705 to 0.10418, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.1447 - accuracy: 0.9513 - val_loss: 0.1042 - val_accuracy: 0.9500\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.9588\n",
      "Epoch 00025: val_loss improved from 0.10418 to 0.10304, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1284 - accuracy: 0.9588 - val_loss: 0.1030 - val_accuracy: 0.9600\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.9538\n",
      "Epoch 00026: val_loss improved from 0.10304 to 0.09334, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.1148 - accuracy: 0.9538 - val_loss: 0.0933 - val_accuracy: 0.9500\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9638\n",
      "Epoch 00027: val_loss improved from 0.09334 to 0.06974, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1003 - accuracy: 0.9638 - val_loss: 0.0697 - val_accuracy: 0.9800\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9775\n",
      "Epoch 00028: val_loss did not improve from 0.06974\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0940 - accuracy: 0.9775 - val_loss: 0.0732 - val_accuracy: 0.9700\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1020 - accuracy: 0.9737\n",
      "Epoch 00029: val_loss improved from 0.06974 to 0.05668, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.1020 - accuracy: 0.9737 - val_loss: 0.0567 - val_accuracy: 0.9800\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9787\n",
      "Epoch 00030: val_loss improved from 0.05668 to 0.05151, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0779 - accuracy: 0.9787 - val_loss: 0.0515 - val_accuracy: 0.9900\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9750\n",
      "Epoch 00031: val_loss did not improve from 0.05151\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0841 - accuracy: 0.9750 - val_loss: 0.0685 - val_accuracy: 0.9800\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9737\n",
      "Epoch 00032: val_loss improved from 0.05151 to 0.04626, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0847 - accuracy: 0.9737 - val_loss: 0.0463 - val_accuracy: 0.9900\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9825\n",
      "Epoch 00033: val_loss improved from 0.04626 to 0.04364, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.0588 - accuracy: 0.9825 - val_loss: 0.0436 - val_accuracy: 0.9800\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9762\n",
      "Epoch 00034: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0765 - accuracy: 0.9762 - val_loss: 0.0572 - val_accuracy: 0.9800\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9925\n",
      "Epoch 00035: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0552 - accuracy: 0.9925 - val_loss: 0.0728 - val_accuracy: 0.9800\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.9850\n",
      "Epoch 00036: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0610 - accuracy: 0.9850 - val_loss: 0.0608 - val_accuracy: 0.9900\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9950\n",
      "Epoch 00037: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0460 - accuracy: 0.9950 - val_loss: 0.0524 - val_accuracy: 0.9900\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9937\n",
      "Epoch 00038: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0473 - accuracy: 0.9937 - val_loss: 0.0547 - val_accuracy: 0.9900\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9900\n",
      "Epoch 00039: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0501 - accuracy: 0.9900 - val_loss: 0.0562 - val_accuracy: 0.9900\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9887\n",
      "Epoch 00040: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0476 - accuracy: 0.9887 - val_loss: 0.0640 - val_accuracy: 0.9900\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9912\n",
      "Epoch 00041: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0457 - accuracy: 0.9912 - val_loss: 0.0653 - val_accuracy: 0.9900\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9925\n",
      "Epoch 00042: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0406 - accuracy: 0.9925 - val_loss: 0.0581 - val_accuracy: 0.9900\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9925\n",
      "Epoch 00043: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0377 - accuracy: 0.9925 - val_loss: 0.0550 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9937\n",
      "Epoch 00044: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0327 - accuracy: 0.9937 - val_loss: 0.0565 - val_accuracy: 0.9900\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9937\n",
      "Epoch 00045: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0376 - accuracy: 0.9937 - val_loss: 0.0614 - val_accuracy: 0.9900\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9925\n",
      "Epoch 00046: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0324 - accuracy: 0.9925 - val_loss: 0.0641 - val_accuracy: 0.9900\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9950\n",
      "Epoch 00047: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0312 - accuracy: 0.9950 - val_loss: 0.0635 - val_accuracy: 0.9900\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9962\n",
      "Epoch 00048: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0309 - accuracy: 0.9962 - val_loss: 0.0636 - val_accuracy: 0.9900\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9962\n",
      "Epoch 00049: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0275 - accuracy: 0.9962 - val_loss: 0.0633 - val_accuracy: 0.9900\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9962\n",
      "Epoch 00050: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0269 - accuracy: 0.9962 - val_loss: 0.0628 - val_accuracy: 0.9900\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9950\n",
      "Epoch 00051: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0312 - accuracy: 0.9950 - val_loss: 0.0616 - val_accuracy: 0.9900\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9962\n",
      "Epoch 00052: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0240 - accuracy: 0.9962 - val_loss: 0.0603 - val_accuracy: 0.9900\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9962\n",
      "Epoch 00053: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0236 - accuracy: 0.9962 - val_loss: 0.0611 - val_accuracy: 0.9900\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9950\n",
      "Epoch 00054: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0268 - accuracy: 0.9950 - val_loss: 0.0624 - val_accuracy: 0.9900\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9962\n",
      "Epoch 00055: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0225 - accuracy: 0.9962 - val_loss: 0.0663 - val_accuracy: 0.9900\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9937\n",
      "Epoch 00056: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0243 - accuracy: 0.9937 - val_loss: 0.0702 - val_accuracy: 0.9900\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9937\n",
      "Epoch 00057: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0215 - accuracy: 0.9937 - val_loss: 0.0689 - val_accuracy: 0.9900\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9937\n",
      "Epoch 00058: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 0.0731 - val_accuracy: 0.9900\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9937\n",
      "Epoch 00059: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0234 - accuracy: 0.9937 - val_loss: 0.0711 - val_accuracy: 0.9900\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9950\n",
      "Epoch 00060: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.0210 - accuracy: 0.9950 - val_loss: 0.0673 - val_accuracy: 0.9900\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9950\n",
      "Epoch 00061: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0177 - accuracy: 0.9950 - val_loss: 0.0616 - val_accuracy: 0.9900\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9962\n",
      "Epoch 00062: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.0612 - val_accuracy: 0.9900\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9950\n",
      "Epoch 00063: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0170 - accuracy: 0.9950 - val_loss: 0.0587 - val_accuracy: 0.9900\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9950\n",
      "Epoch 00064: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 0.0530 - val_accuracy: 0.9900\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9925\n",
      "Epoch 00065: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0170 - accuracy: 0.9925 - val_loss: 0.0528 - val_accuracy: 0.9900\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9987\n",
      "Epoch 00066: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0094 - accuracy: 0.9987 - val_loss: 0.0541 - val_accuracy: 0.9900\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9962\n",
      "Epoch 00067: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0094 - accuracy: 0.9962 - val_loss: 0.0533 - val_accuracy: 0.9900\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9962\n",
      "Epoch 00068: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.0503 - val_accuracy: 0.9900\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9975\n",
      "Epoch 00069: val_loss improved from 0.04364 to 0.03235, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.0324 - val_accuracy: 0.9900\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9975\n",
      "Epoch 00070: val_loss improved from 0.03235 to 0.01944, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0064 - accuracy: 0.9975 - val_loss: 0.0194 - val_accuracy: 0.9900\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9950\n",
      "Epoch 00071: val_loss did not improve from 0.01944\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0101 - accuracy: 0.9950 - val_loss: 0.0312 - val_accuracy: 0.9900\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9962\n",
      "Epoch 00072: val_loss did not improve from 0.01944\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0100 - accuracy: 0.9962 - val_loss: 0.0539 - val_accuracy: 0.9900\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9975\n",
      "Epoch 00073: val_loss did not improve from 0.01944\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.0486 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9962\n",
      "Epoch 00074: val_loss did not improve from 0.01944\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0092 - accuracy: 0.9962 - val_loss: 0.0211 - val_accuracy: 0.9900\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9987\n",
      "Epoch 00075: val_loss improved from 0.01944 to 0.00596, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9975\n",
      "Epoch 00076: val_loss improved from 0.00596 to 0.00467, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0056 - accuracy: 0.9975 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9962\n",
      "Epoch 00077: val_loss did not improve from 0.00467\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.0144 - val_accuracy: 0.9900\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9962\n",
      "Epoch 00078: val_loss did not improve from 0.00467\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0054 - accuracy: 0.9962 - val_loss: 0.0386 - val_accuracy: 0.9900\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 00079: val_loss did not improve from 0.00467\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0396 - val_accuracy: 0.9900\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9950\n",
      "Epoch 00080: val_loss did not improve from 0.00467\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.0093 - accuracy: 0.9950 - val_loss: 0.0165 - val_accuracy: 0.9900\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 00081: val_loss did not improve from 0.00467\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9987\n",
      "Epoch 00082: val_loss improved from 0.00467 to 0.00331, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9975\n",
      "Epoch 00083: val_loss did not improve from 0.00331\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.0085 - val_accuracy: 0.9900\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9987\n",
      "Epoch 00084: val_loss did not improve from 0.00331\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.0176 - val_accuracy: 0.9900\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 00085: val_loss did not improve from 0.00331\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9900\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9975\n",
      "Epoch 00086: val_loss did not improve from 0.00331\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 00087: val_loss improved from 0.00331 to 0.00101, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 00088: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 00089: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9987\n",
      "Epoch 00090: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9975\n",
      "Epoch 00091: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.0176 - val_accuracy: 0.9900\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 00092: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9900\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9975\n",
      "Epoch 00093: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0060 - accuracy: 0.9975 - val_loss: 0.0219 - val_accuracy: 0.9900\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9987\n",
      "Epoch 00094: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 0.0119 - val_accuracy: 0.9900\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 00095: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.9481e-04 - accuracy: 1.0000\n",
      "Epoch 00096: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 7.9481e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 00097: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 00098: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 00099: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0093 - val_accuracy: 0.9900\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.6386e-04 - accuracy: 1.0000\n",
      "Epoch 00100: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 9.6386e-04 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9900\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9987\n",
      "Epoch 00101: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0013 - accuracy: 0.9987 - val_loss: 0.0281 - val_accuracy: 0.9900\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.9245e-04 - accuracy: 1.0000\n",
      "Epoch 00102: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 4.9245e-04 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9900\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9937\n",
      "Epoch 00103: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0141 - accuracy: 0.9937 - val_loss: 0.0264 - val_accuracy: 0.9900\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9987\n",
      "Epoch 00104: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0016 - accuracy: 0.9987 - val_loss: 0.0287 - val_accuracy: 0.9900\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9975\n",
      "Epoch 00105: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0034 - accuracy: 0.9975 - val_loss: 0.0471 - val_accuracy: 0.9800\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9950\n",
      "Epoch 00106: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0117 - accuracy: 0.9950 - val_loss: 0.0147 - val_accuracy: 0.9900\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.7674e-04 - accuracy: 1.0000\n",
      "Epoch 00107: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 8.7674e-04 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9900\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9987\n",
      "Epoch 00108: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 0.0186 - val_accuracy: 0.9900\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9950\n",
      "Epoch 00109: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0127 - accuracy: 0.9950 - val_loss: 0.0351 - val_accuracy: 0.9900\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 00110: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9900\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9975\n",
      "Epoch 00111: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0044 - accuracy: 0.9975 - val_loss: 0.0848 - val_accuracy: 0.9900\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9987\n",
      "Epoch 00112: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 0.1027 - val_accuracy: 0.9900\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9962\n",
      "Epoch 00113: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.0786 - val_accuracy: 0.9900\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.8191e-04 - accuracy: 1.0000\n",
      "Epoch 00114: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 7.8191e-04 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9900\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9987\n",
      "Epoch 00115: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 0.0297 - val_accuracy: 0.9900\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9987\n",
      "Epoch 00116: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.0240 - val_accuracy: 0.9900\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.5558e-04 - accuracy: 1.0000\n",
      "Epoch 00117: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 7.5558e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9900\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.4837e-04 - accuracy: 1.0000\n",
      "Epoch 00118: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 8.4837e-04 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9900\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 00119: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9900\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7161e-04 - accuracy: 1.0000\n",
      "Epoch 00120: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.7161e-04 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9900\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1497e-04 - accuracy: 1.0000\n",
      "Epoch 00121: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.1497e-04 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9900\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9987\n",
      "Epoch 00122: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0013 - accuracy: 0.9987 - val_loss: 0.0415 - val_accuracy: 0.9900\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1018e-04 - accuracy: 1.0000\n",
      "Epoch 00123: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 5.1018e-04 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9900\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.2870e-04 - accuracy: 1.0000\n",
      "Epoch 00124: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 4.2870e-04 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9900\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9987\n",
      "Epoch 00125: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0012 - accuracy: 0.9987 - val_loss: 0.0344 - val_accuracy: 0.9900\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9975\n",
      "Epoch 00126: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0054 - accuracy: 0.9975 - val_loss: 0.0400 - val_accuracy: 0.9900\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.9947e-04 - accuracy: 1.0000\n",
      "Epoch 00127: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 6.9947e-04 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9900\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.5121e-04 - accuracy: 1.0000\n",
      "Epoch 00128: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.5121e-04 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9900\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.3070e-04 - accuracy: 1.0000\n",
      "Epoch 00129: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 6.3070e-04 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9900\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.6492e-04 - accuracy: 1.0000\n",
      "Epoch 00130: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 3.6492e-04 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9900\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9987\n",
      "Epoch 00131: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 0.0300 - val_accuracy: 0.9900\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4026e-04 - accuracy: 1.0000\n",
      "Epoch 00132: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 2.4026e-04 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2860e-04 - accuracy: 1.0000\n",
      "Epoch 00133: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 1.2860e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.5675e-04 - accuracy: 1.0000\n",
      "Epoch 00134: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 2.5675e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6576e-04 - accuracy: 1.0000\n",
      "Epoch 00135: val_loss improved from 0.00101 to 0.00031, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 1.6576e-04 - accuracy: 1.0000 - val_loss: 3.0592e-04 - val_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1666e-04 - accuracy: 1.0000\n",
      "Epoch 00136: val_loss improved from 0.00031 to 0.00012, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 2.1666e-04 - accuracy: 1.0000 - val_loss: 1.1941e-04 - val_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 00137: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 1.6035e-04 - val_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9987\n",
      "Epoch 00138: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 5.4940e-04 - val_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0860e-04 - accuracy: 1.0000\n",
      "Epoch 00139: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.0860e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3760e-04 - accuracy: 1.0000\n",
      "Epoch 00140: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.3760e-04 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.3376e-05 - accuracy: 1.0000\n",
      "Epoch 00141: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 7.3376e-05 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9900\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5339e-04 - accuracy: 1.0000\n",
      "Epoch 00142: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.5339e-04 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9900\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2227e-04 - accuracy: 1.0000\n",
      "Epoch 00143: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 3.2227e-04 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9900\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5379e-04 - accuracy: 1.0000\n",
      "Epoch 00144: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 1.5379e-04 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9900\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.5633e-04 - accuracy: 1.0000\n",
      "Epoch 00145: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 8.5633e-04 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9900\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9987\n",
      "Epoch 00146: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 0.0184 - val_accuracy: 0.9900\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4504e-04 - accuracy: 1.0000\n",
      "Epoch 00147: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.4504e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.8670e-04 - accuracy: 1.0000\n",
      "Epoch 00148: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 4.8670e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0778e-04 - accuracy: 1.0000\n",
      "Epoch 00149: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 3.0778e-04 - accuracy: 1.0000 - val_loss: 2.9025e-04 - val_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4671e-04 - accuracy: 1.0000\n",
      "Epoch 00150: val_loss improved from 0.00012 to 0.00011, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 2.4671e-04 - accuracy: 1.0000 - val_loss: 1.0836e-04 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9987\n",
      "Epoch 00151: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.6290e-04 - val_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2695e-04 - accuracy: 1.0000\n",
      "Epoch 00152: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 1.2695e-04 - accuracy: 1.0000 - val_loss: 2.4230e-04 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.1505e-05 - accuracy: 1.0000\n",
      "Epoch 00153: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 4.1505e-05 - accuracy: 1.0000 - val_loss: 3.4840e-04 - val_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.2961e-05 - accuracy: 1.0000\n",
      "Epoch 00154: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 6.2961e-05 - accuracy: 1.0000 - val_loss: 4.8553e-04 - val_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1272e-04 - accuracy: 1.0000\n",
      "Epoch 00155: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 1.1272e-04 - accuracy: 1.0000 - val_loss: 6.5851e-04 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.6191e-05 - accuracy: 1.0000\n",
      "Epoch 00156: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 9.6191e-05 - accuracy: 1.0000 - val_loss: 8.1215e-04 - val_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9679e-04 - accuracy: 1.0000\n",
      "Epoch 00157: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 2.9679e-04 - accuracy: 1.0000 - val_loss: 8.3871e-04 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.6160e-04 - accuracy: 1.0000\n",
      "Epoch 00158: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 6.6160e-04 - accuracy: 1.0000 - val_loss: 6.1170e-04 - val_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.2183e-05 - accuracy: 1.0000\n",
      "Epoch 00159: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 6.2183e-05 - accuracy: 1.0000 - val_loss: 4.3804e-04 - val_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.7012e-04 - accuracy: 1.0000\n",
      "Epoch 00160: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 5.7012e-04 - accuracy: 1.0000 - val_loss: 2.9503e-04 - val_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.2479e-05 - accuracy: 1.0000\n",
      "Epoch 00161: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 5.2479e-05 - accuracy: 1.0000 - val_loss: 2.0204e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2906e-05 - accuracy: 1.0000\n",
      "Epoch 00162: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 9.2906e-05 - accuracy: 1.0000 - val_loss: 1.4143e-04 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.3648e-05 - accuracy: 1.0000\n",
      "Epoch 00163: val_loss improved from 0.00011 to 0.00010, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 4.3648e-05 - accuracy: 1.0000 - val_loss: 1.0448e-04 - val_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.8413e-05 - accuracy: 1.0000\n",
      "Epoch 00164: val_loss improved from 0.00010 to 0.00008, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 9.8413e-05 - accuracy: 1.0000 - val_loss: 7.7500e-05 - val_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0662e-04 - accuracy: 1.0000\n",
      "Epoch 00165: val_loss improved from 0.00008 to 0.00006, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 1.0662e-04 - accuracy: 1.0000 - val_loss: 5.5432e-05 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.2414e-05 - accuracy: 1.0000\n",
      "Epoch 00166: val_loss improved from 0.00006 to 0.00004, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 8.2414e-05 - accuracy: 1.0000 - val_loss: 4.2203e-05 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.3880e-05 - accuracy: 1.0000\n",
      "Epoch 00167: val_loss improved from 0.00004 to 0.00003, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 4.3880e-05 - accuracy: 1.0000 - val_loss: 3.3134e-05 - val_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3865e-05 - accuracy: 1.0000\n",
      "Epoch 00168: val_loss improved from 0.00003 to 0.00003, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 2.3865e-05 - accuracy: 1.0000 - val_loss: 2.6960e-05 - val_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7759e-05 - accuracy: 1.0000\n",
      "Epoch 00169: val_loss improved from 0.00003 to 0.00002, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 1.7759e-05 - accuracy: 1.0000 - val_loss: 2.2762e-05 - val_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1456e-05 - accuracy: 1.0000\n",
      "Epoch 00170: val_loss improved from 0.00002 to 0.00002, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 5.1456e-05 - accuracy: 1.0000 - val_loss: 1.9711e-05 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9315e-05 - accuracy: 1.0000\n",
      "Epoch 00171: val_loss improved from 0.00002 to 0.00002, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 2.9315e-05 - accuracy: 1.0000 - val_loss: 1.7698e-05 - val_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.8223e-05 - accuracy: 1.0000\n",
      "Epoch 00172: val_loss improved from 0.00002 to 0.00002, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 3.8223e-05 - accuracy: 1.0000 - val_loss: 1.6165e-05 - val_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2625e-04 - accuracy: 1.0000\n",
      "Epoch 00173: val_loss improved from 0.00002 to 0.00002, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 1.2625e-04 - accuracy: 1.0000 - val_loss: 1.5827e-05 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.0989e-04 - accuracy: 1.0000\n",
      "Epoch 00174: val_loss did not improve from 0.00002\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 5.0989e-04 - accuracy: 1.0000 - val_loss: 1.9255e-05 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.3357e-05 - accuracy: 1.0000\n",
      "Epoch 00175: val_loss did not improve from 0.00002\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 9.3357e-05 - accuracy: 1.0000 - val_loss: 2.1886e-05 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.7719e-04 - accuracy: 1.0000\n",
      "Epoch 00176: val_loss did not improve from 0.00002\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.7719e-04 - accuracy: 1.0000 - val_loss: 3.1843e-05 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.8113e-05 - accuracy: 1.0000\n",
      "Epoch 00177: val_loss did not improve from 0.00002\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 6.8113e-05 - accuracy: 1.0000 - val_loss: 4.7285e-05 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9987\n",
      "Epoch 00178: val_loss did not improve from 0.00002\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0017 - accuracy: 0.9987 - val_loss: 2.1958e-05 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.6264e-04 - accuracy: 1.0000\n",
      "Epoch 00179: val_loss improved from 0.00002 to 0.00001, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 2.6264e-04 - accuracy: 1.0000 - val_loss: 1.2641e-05 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.0369e-05 - accuracy: 1.0000\n",
      "Epoch 00180: val_loss improved from 0.00001 to 0.00001, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 9.0369e-05 - accuracy: 1.0000 - val_loss: 9.2833e-06 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4922e-04 - accuracy: 1.0000\n",
      "Epoch 00181: val_loss improved from 0.00001 to 0.00001, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 1.4922e-04 - accuracy: 1.0000 - val_loss: 7.9697e-06 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.1428e-05 - accuracy: 1.0000\n",
      "Epoch 00182: val_loss improved from 0.00001 to 0.00001, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 9.1428e-05 - accuracy: 1.0000 - val_loss: 7.2940e-06 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9987\n",
      "Epoch 00183: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 7.8562e-06 - val_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9987\n",
      "Epoch 00184: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 3.8672e-05 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0451e-04 - accuracy: 1.0000\n",
      "Epoch 00185: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 3.0451e-04 - accuracy: 1.0000 - val_loss: 4.4004e-04 - val_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.8667e-05 - accuracy: 1.0000\n",
      "Epoch 00186: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 6.8667e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9987\n",
      "Epoch 00187: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 0.0070 - val_accuracy: 0.9900\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.6005e-04 - accuracy: 1.0000\n",
      "Epoch 00188: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 5.6005e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.3892e-04 - accuracy: 1.0000\n",
      "Epoch 00189: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 8.3892e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.5200e-04 - accuracy: 1.0000\n",
      "Epoch 00190: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 3.5200e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2432e-04 - accuracy: 1.0000\n",
      "Epoch 00191: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 2.2432e-04 - accuracy: 1.0000 - val_loss: 5.0212e-04 - val_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.6237e-04 - accuracy: 1.0000\n",
      "Epoch 00192: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 5.6237e-04 - accuracy: 1.0000 - val_loss: 1.5275e-04 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.0127e-05 - accuracy: 1.0000\n",
      "Epoch 00193: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 6.0127e-05 - accuracy: 1.0000 - val_loss: 5.1675e-05 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.2577e-05 - accuracy: 1.0000\n",
      "Epoch 00194: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 5.2577e-05 - accuracy: 1.0000 - val_loss: 2.0506e-05 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.6759e-05 - accuracy: 1.0000\n",
      "Epoch 00195: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 2.6759e-05 - accuracy: 1.0000 - val_loss: 9.7590e-06 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.4126e-04 - accuracy: 1.0000\n",
      "Epoch 00196: val_loss improved from 0.00001 to 0.00000, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 8.4126e-04 - accuracy: 1.0000 - val_loss: 3.2687e-06 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.3828e-05 - accuracy: 1.0000\n",
      "Epoch 00197: val_loss improved from 0.00000 to 0.00000, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 4.3828e-05 - accuracy: 1.0000 - val_loss: 2.6667e-06 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.0998e-04 - accuracy: 1.0000\n",
      "Epoch 00198: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 4.0998e-04 - accuracy: 1.0000 - val_loss: 3.1926e-06 - val_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9975\n",
      "Epoch 00199: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0056 - accuracy: 0.9975 - val_loss: 3.3736e-06 - val_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.4635e-05 - accuracy: 1.0000\n",
      "Epoch 00200: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 9.4635e-05 - accuracy: 1.0000 - val_loss: 1.0620e-05 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.9156e-04 - accuracy: 1.0000\n",
      "Epoch 00201: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 5.9156e-04 - accuracy: 1.0000 - val_loss: 4.7464e-05 - val_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2018e-04 - accuracy: 1.0000\n",
      "Epoch 00202: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 2.2018e-04 - accuracy: 1.0000 - val_loss: 2.4137e-04 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.7124e-04 - accuracy: 1.0000\n",
      "Epoch 00203: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 4.7124e-04 - accuracy: 1.0000 - val_loss: 7.8133e-04 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0495e-04 - accuracy: 1.0000\n",
      "Epoch 00204: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.0495e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9987\n",
      "Epoch 00205: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.7553e-04 - accuracy: 1.0000\n",
      "Epoch 00206: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 9.7553e-04 - accuracy: 1.0000 - val_loss: 1.8936e-04 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.5906e-05 - accuracy: 1.0000\n",
      "Epoch 00207: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 8.5906e-05 - accuracy: 1.0000 - val_loss: 4.0188e-05 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.6360e-05 - accuracy: 1.0000\n",
      "Epoch 00208: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 8.6360e-05 - accuracy: 1.0000 - val_loss: 1.2205e-05 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.6022e-05 - accuracy: 1.0000\n",
      "Epoch 00209: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2.6022e-05 - accuracy: 1.0000 - val_loss: 5.7978e-06 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7276e-05 - accuracy: 1.0000\n",
      "Epoch 00210: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.7276e-05 - accuracy: 1.0000 - val_loss: 3.8640e-06 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.7088e-04 - accuracy: 1.0000\n",
      "Epoch 00211: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 4.7088e-04 - accuracy: 1.0000 - val_loss: 3.0248e-06 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9987\n",
      "Epoch 00212: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 3.0961e-06 - val_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.9864e-04 - accuracy: 1.0000\n",
      "Epoch 00213: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 8.9864e-04 - accuracy: 1.0000 - val_loss: 7.5662e-06 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2190e-05 - accuracy: 1.0000\n",
      "Epoch 00214: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.2190e-05 - accuracy: 1.0000 - val_loss: 3.6567e-05 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.3390e-04 - accuracy: 1.0000\n",
      "Epoch 00215: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 8.3390e-04 - accuracy: 1.0000 - val_loss: 4.3320e-04 - val_accuracy: 1.0000\n",
      "Epoch 216/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-5600db0e85ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     23\u001b[0m model.fit(train_x,y_one_hot, epochs=500,batch_size=N,verbose=1,\n\u001b[0;32m---> 24\u001b[0;31m           validation_data=(val_x,val_y_one_hot),callbacks=[checkpoint])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate= 0.001)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('models/cnn.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "# build the model and train it\n",
    "model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, (3, 3),padding='same',activation=\"relu\",input_shape=(32, 32,1)),\n",
    "      tf.keras.layers.Conv2D(32, (3, 3),activation=\"relu\",input_shape=(32, 32,32)),  \n",
    "      tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2), padding='valid'),\n",
    "      tf.keras.layers.Dropout(0.25),\n",
    "      tf.keras.layers.Conv2D(64, (3, 3),padding='same',activation=\"relu\",input_shape=(15, 15,32)),  \n",
    "      tf.keras.layers.Conv2D(64, (3, 3),activation=\"relu\",input_shape=(15, 15,64)),  \n",
    "      tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2), padding='valid'),\n",
    "      tf.keras.layers.Dropout(0.25),\n",
    "      tf.keras.layers.Flatten(),  \n",
    "      tf.keras.layers.Dense(512, activation=\"relu\")  ,\n",
    "      tf.keras.layers.Dropout(0.5),\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(2)  \n",
    "])\n",
    "model.summary()\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_x,y_one_hot, epochs=500,batch_size=N,verbose=1,\n",
    "          validation_data=(val_x,val_y_one_hot),callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.9712499976158142\n",
      "Validation accuracy:  0.9800000190734863\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(test_x)\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "print('Training accuracy: ', acc[-1])\n",
    "print('Validation accuracy: ', val_acc[-1])\n",
    "\n",
    "confusion = tf.math.confusion_matrix(\n",
    "    labels=tf.constant(test_y.flatten()),\n",
    "    predictions=tf.constant(index_of_max(predictions)),\n",
    "    num_classes=2)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(confusion, xticklabels=['0','1'], yticklabels=['0','1'], \n",
    "            annot=True, fmt='g'),\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

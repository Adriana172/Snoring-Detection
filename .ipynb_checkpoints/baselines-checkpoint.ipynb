{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6a529ba05314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/249r/assignments-Adriana172/Snoring-Detection/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipdb'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append('./')\n",
    "from utils import load_dataset\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, val_x, train_y, test_y, val_y, x_mean, x_std = load_dataset()\n",
    "N = train_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot = tf.one_hot(train_y,depth=2)\n",
    "val_y_one_hot = tf.one_hot(val_y,depth=2)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate= 0.005)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('models/lr.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8826 - accuracy: 0.4725\n",
      "Epoch 00001: val_loss improved from inf to 0.48633, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8826 - accuracy: 0.4725 - val_loss: 0.4863 - val_accuracy: 0.8800\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4339 - accuracy: 0.8888\n",
      "Epoch 00002: val_loss did not improve from 0.48633\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.4339 - accuracy: 0.8888 - val_loss: 0.6161 - val_accuracy: 0.8800\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.9000\n",
      "Epoch 00003: val_loss did not improve from 0.48633\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5412 - accuracy: 0.9000 - val_loss: 0.6396 - val_accuracy: 0.8800\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5701 - accuracy: 0.9000\n",
      "Epoch 00004: val_loss did not improve from 0.48633\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5701 - accuracy: 0.9000 - val_loss: 0.5927 - val_accuracy: 0.8800\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5397 - accuracy: 0.9000\n",
      "Epoch 00005: val_loss did not improve from 0.48633\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5397 - accuracy: 0.9000 - val_loss: 0.5385 - val_accuracy: 0.8800\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5058 - accuracy: 0.9000\n",
      "Epoch 00006: val_loss did not improve from 0.48633\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5058 - accuracy: 0.9000 - val_loss: 0.5481 - val_accuracy: 0.8800\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5409 - accuracy: 0.9000\n",
      "Epoch 00007: val_loss did not improve from 0.48633\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5409 - accuracy: 0.9000 - val_loss: 0.4988 - val_accuracy: 0.8800\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5056 - accuracy: 0.9000\n",
      "Epoch 00008: val_loss improved from 0.48633 to 0.40733, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.5056 - accuracy: 0.9000 - val_loss: 0.4073 - val_accuracy: 0.8800\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4196 - accuracy: 0.9000\n",
      "Epoch 00009: val_loss improved from 0.40733 to 0.34720, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4196 - accuracy: 0.9000 - val_loss: 0.3472 - val_accuracy: 0.8800\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3678 - accuracy: 0.9025\n",
      "Epoch 00010: val_loss improved from 0.34720 to 0.30271, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.3678 - accuracy: 0.9025 - val_loss: 0.3027 - val_accuracy: 0.9100\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3321 - accuracy: 0.9075\n",
      "Epoch 00011: val_loss improved from 0.30271 to 0.26614, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.3321 - accuracy: 0.9075 - val_loss: 0.2661 - val_accuracy: 0.9200\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3011 - accuracy: 0.9137\n",
      "Epoch 00012: val_loss improved from 0.26614 to 0.25009, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3011 - accuracy: 0.9137 - val_loss: 0.2501 - val_accuracy: 0.9300\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2926 - accuracy: 0.9250\n",
      "Epoch 00013: val_loss did not improve from 0.25009\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2926 - accuracy: 0.9250 - val_loss: 0.2565 - val_accuracy: 0.9300\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3131 - accuracy: 0.9187\n",
      "Epoch 00014: val_loss did not improve from 0.25009\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3131 - accuracy: 0.9187 - val_loss: 0.2591 - val_accuracy: 0.9400\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3308 - accuracy: 0.9150\n",
      "Epoch 00015: val_loss improved from 0.25009 to 0.23883, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.3308 - accuracy: 0.9150 - val_loss: 0.2388 - val_accuracy: 0.9300\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3211 - accuracy: 0.9075\n",
      "Epoch 00016: val_loss improved from 0.23883 to 0.20512, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.3211 - accuracy: 0.9075 - val_loss: 0.2051 - val_accuracy: 0.9400\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2916 - accuracy: 0.9100\n",
      "Epoch 00017: val_loss improved from 0.20512 to 0.17580, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2916 - accuracy: 0.9100 - val_loss: 0.1758 - val_accuracy: 0.9300\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2597 - accuracy: 0.9162\n",
      "Epoch 00018: val_loss improved from 0.17580 to 0.16421, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2597 - accuracy: 0.9162 - val_loss: 0.1642 - val_accuracy: 0.9300\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2426 - accuracy: 0.9187\n",
      "Epoch 00019: val_loss did not improve from 0.16421\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2426 - accuracy: 0.9187 - val_loss: 0.1718 - val_accuracy: 0.9300\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2455 - accuracy: 0.9225\n",
      "Epoch 00020: val_loss did not improve from 0.16421\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2455 - accuracy: 0.9225 - val_loss: 0.1877 - val_accuracy: 0.9400\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2580 - accuracy: 0.9187\n",
      "Epoch 00021: val_loss did not improve from 0.16421\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2580 - accuracy: 0.9187 - val_loss: 0.1982 - val_accuracy: 0.9300\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2662 - accuracy: 0.9175\n",
      "Epoch 00022: val_loss did not improve from 0.16421\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2662 - accuracy: 0.9175 - val_loss: 0.1959 - val_accuracy: 0.9300\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.9162\n",
      "Epoch 00023: val_loss did not improve from 0.16421\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2632 - accuracy: 0.9162 - val_loss: 0.1820 - val_accuracy: 0.9300\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2500 - accuracy: 0.9162\n",
      "Epoch 00024: val_loss improved from 0.16421 to 0.16327, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2500 - accuracy: 0.9162 - val_loss: 0.1633 - val_accuracy: 0.9400\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2337 - accuracy: 0.9137\n",
      "Epoch 00025: val_loss improved from 0.16327 to 0.14901, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2337 - accuracy: 0.9137 - val_loss: 0.1490 - val_accuracy: 0.9300\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2231 - accuracy: 0.9237\n",
      "Epoch 00026: val_loss improved from 0.14901 to 0.14408, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.2231 - accuracy: 0.9237 - val_loss: 0.1441 - val_accuracy: 0.9300\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2219 - accuracy: 0.9137\n",
      "Epoch 00027: val_loss did not improve from 0.14408\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2219 - accuracy: 0.9137 - val_loss: 0.1458 - val_accuracy: 0.9500\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2249 - accuracy: 0.9137\n",
      "Epoch 00028: val_loss did not improve from 0.14408\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2249 - accuracy: 0.9137 - val_loss: 0.1494 - val_accuracy: 0.9400\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 0.9137\n",
      "Epoch 00029: val_loss did not improve from 0.14408\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2259 - accuracy: 0.9137 - val_loss: 0.1520 - val_accuracy: 0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.9175\n",
      "Epoch 00030: val_loss did not improve from 0.14408\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2225 - accuracy: 0.9175 - val_loss: 0.1526 - val_accuracy: 0.9300\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2155 - accuracy: 0.9200\n",
      "Epoch 00031: val_loss did not improve from 0.14408\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2155 - accuracy: 0.9200 - val_loss: 0.1521 - val_accuracy: 0.9400\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2076 - accuracy: 0.9187\n",
      "Epoch 00032: val_loss did not improve from 0.14408\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2076 - accuracy: 0.9187 - val_loss: 0.1519 - val_accuracy: 0.9400\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2018 - accuracy: 0.9237\n",
      "Epoch 00033: val_loss did not improve from 0.14408\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2018 - accuracy: 0.9237 - val_loss: 0.1522 - val_accuracy: 0.9400\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1985 - accuracy: 0.9175\n",
      "Epoch 00034: val_loss did not improve from 0.14408\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1985 - accuracy: 0.9175 - val_loss: 0.1526 - val_accuracy: 0.9400\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1972 - accuracy: 0.9175\n",
      "Epoch 00035: val_loss did not improve from 0.14408\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1972 - accuracy: 0.9175 - val_loss: 0.1527 - val_accuracy: 0.9400\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1970 - accuracy: 0.9187\n",
      "Epoch 00036: val_loss did not improve from 0.14408\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1970 - accuracy: 0.9187 - val_loss: 0.1519 - val_accuracy: 0.9400\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1959 - accuracy: 0.9225\n",
      "Epoch 00037: val_loss did not improve from 0.14408\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.1959 - accuracy: 0.9225 - val_loss: 0.1490 - val_accuracy: 0.9400\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1920 - accuracy: 0.9237\n",
      "Epoch 00038: val_loss did not improve from 0.14408\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1920 - accuracy: 0.9237 - val_loss: 0.1454 - val_accuracy: 0.9400\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1865 - accuracy: 0.9237\n",
      "Epoch 00039: val_loss improved from 0.14408 to 0.14352, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1865 - accuracy: 0.9237 - val_loss: 0.1435 - val_accuracy: 0.9400\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1833 - accuracy: 0.9262\n",
      "Epoch 00040: val_loss did not improve from 0.14352\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1833 - accuracy: 0.9262 - val_loss: 0.1440 - val_accuracy: 0.9400\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1835 - accuracy: 0.9275\n",
      "Epoch 00041: val_loss did not improve from 0.14352\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1835 - accuracy: 0.9275 - val_loss: 0.1445 - val_accuracy: 0.9500\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1844 - accuracy: 0.9325\n",
      "Epoch 00042: val_loss improved from 0.14352 to 0.14249, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1844 - accuracy: 0.9325 - val_loss: 0.1425 - val_accuracy: 0.9500\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1829 - accuracy: 0.9362\n",
      "Epoch 00043: val_loss improved from 0.14249 to 0.13808, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1829 - accuracy: 0.9362 - val_loss: 0.1381 - val_accuracy: 0.9500\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1789 - accuracy: 0.9362\n",
      "Epoch 00044: val_loss improved from 0.13808 to 0.13376, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.1789 - accuracy: 0.9362 - val_loss: 0.1338 - val_accuracy: 0.9500\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1750 - accuracy: 0.9350\n",
      "Epoch 00045: val_loss improved from 0.13376 to 0.13128, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1750 - accuracy: 0.9350 - val_loss: 0.1313 - val_accuracy: 0.9400\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1729 - accuracy: 0.9300\n",
      "Epoch 00046: val_loss improved from 0.13128 to 0.13012, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1729 - accuracy: 0.9300 - val_loss: 0.1301 - val_accuracy: 0.9400\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1718 - accuracy: 0.9287\n",
      "Epoch 00047: val_loss improved from 0.13012 to 0.12898, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1718 - accuracy: 0.9287 - val_loss: 0.1290 - val_accuracy: 0.9400\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.9225\n",
      "Epoch 00048: val_loss improved from 0.12898 to 0.12741, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1704 - accuracy: 0.9225 - val_loss: 0.1274 - val_accuracy: 0.9400\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1684 - accuracy: 0.9250\n",
      "Epoch 00049: val_loss improved from 0.12741 to 0.12545, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1684 - accuracy: 0.9250 - val_loss: 0.1255 - val_accuracy: 0.9400\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1662 - accuracy: 0.9262\n",
      "Epoch 00050: val_loss improved from 0.12545 to 0.12307, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1662 - accuracy: 0.9262 - val_loss: 0.1231 - val_accuracy: 0.9400\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1642 - accuracy: 0.9262\n",
      "Epoch 00051: val_loss improved from 0.12307 to 0.12037, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1642 - accuracy: 0.9262 - val_loss: 0.1204 - val_accuracy: 0.9400\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1622 - accuracy: 0.9287\n",
      "Epoch 00052: val_loss improved from 0.12037 to 0.11786, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1622 - accuracy: 0.9287 - val_loss: 0.1179 - val_accuracy: 0.9400\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1608 - accuracy: 0.9287\n",
      "Epoch 00053: val_loss improved from 0.11786 to 0.11596, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1608 - accuracy: 0.9287 - val_loss: 0.1160 - val_accuracy: 0.9600\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1599 - accuracy: 0.9300\n",
      "Epoch 00054: val_loss improved from 0.11596 to 0.11457, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.1599 - accuracy: 0.9300 - val_loss: 0.1146 - val_accuracy: 0.9700\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.9312\n",
      "Epoch 00055: val_loss improved from 0.11457 to 0.11341, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1591 - accuracy: 0.9312 - val_loss: 0.1134 - val_accuracy: 0.9700\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1576 - accuracy: 0.9325\n",
      "Epoch 00056: val_loss improved from 0.11341 to 0.11264, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1576 - accuracy: 0.9325 - val_loss: 0.1126 - val_accuracy: 0.9700\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.9350\n",
      "Epoch 00057: val_loss did not improve from 0.11264\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.1557 - accuracy: 0.9350 - val_loss: 0.1127 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9312\n",
      "Epoch 00058: val_loss did not improve from 0.11264\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1540 - accuracy: 0.9312 - val_loss: 0.1133 - val_accuracy: 0.9400\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1530 - accuracy: 0.9312\n",
      "Epoch 00059: val_loss did not improve from 0.11264\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1530 - accuracy: 0.9312 - val_loss: 0.1137 - val_accuracy: 0.9400\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1522 - accuracy: 0.9312\n",
      "Epoch 00060: val_loss did not improve from 0.11264\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1522 - accuracy: 0.9312 - val_loss: 0.1131 - val_accuracy: 0.9400\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.9325\n",
      "Epoch 00061: val_loss improved from 0.11264 to 0.11160, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1509 - accuracy: 0.9325 - val_loss: 0.1116 - val_accuracy: 0.9400\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1493 - accuracy: 0.9325\n",
      "Epoch 00062: val_loss improved from 0.11160 to 0.10988, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1493 - accuracy: 0.9325 - val_loss: 0.1099 - val_accuracy: 0.9600\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.9337\n",
      "Epoch 00063: val_loss improved from 0.10988 to 0.10855, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1477 - accuracy: 0.9337 - val_loss: 0.1085 - val_accuracy: 0.9800\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1466 - accuracy: 0.9438\n",
      "Epoch 00064: val_loss improved from 0.10855 to 0.10773, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1466 - accuracy: 0.9438 - val_loss: 0.1077 - val_accuracy: 0.9800\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.9488\n",
      "Epoch 00065: val_loss improved from 0.10773 to 0.10729, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1456 - accuracy: 0.9488 - val_loss: 0.1073 - val_accuracy: 0.9800\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 0.9500\n",
      "Epoch 00066: val_loss improved from 0.10729 to 0.10707, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1446 - accuracy: 0.9500 - val_loss: 0.1071 - val_accuracy: 0.9800\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1435 - accuracy: 0.9488\n",
      "Epoch 00067: val_loss improved from 0.10707 to 0.10692, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1435 - accuracy: 0.9488 - val_loss: 0.1069 - val_accuracy: 0.9800\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9488\n",
      "Epoch 00068: val_loss improved from 0.10692 to 0.10666, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1423 - accuracy: 0.9488 - val_loss: 0.1067 - val_accuracy: 0.9700\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1413 - accuracy: 0.9463\n",
      "Epoch 00069: val_loss improved from 0.10666 to 0.10617, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1413 - accuracy: 0.9463 - val_loss: 0.1062 - val_accuracy: 0.9700\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1402 - accuracy: 0.9488\n",
      "Epoch 00070: val_loss improved from 0.10617 to 0.10541, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1402 - accuracy: 0.9488 - val_loss: 0.1054 - val_accuracy: 0.9800\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.9488\n",
      "Epoch 00071: val_loss improved from 0.10541 to 0.10440, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1393 - accuracy: 0.9488 - val_loss: 0.1044 - val_accuracy: 0.9800\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1384 - accuracy: 0.9488\n",
      "Epoch 00072: val_loss improved from 0.10440 to 0.10323, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1384 - accuracy: 0.9488 - val_loss: 0.1032 - val_accuracy: 0.9800\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1373 - accuracy: 0.9513\n",
      "Epoch 00073: val_loss improved from 0.10323 to 0.10203, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1373 - accuracy: 0.9513 - val_loss: 0.1020 - val_accuracy: 0.9800\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9538\n",
      "Epoch 00074: val_loss improved from 0.10203 to 0.10098, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.1362 - accuracy: 0.9538 - val_loss: 0.1010 - val_accuracy: 0.9800\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1352 - accuracy: 0.9563\n",
      "Epoch 00075: val_loss improved from 0.10098 to 0.10013, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1352 - accuracy: 0.9563 - val_loss: 0.1001 - val_accuracy: 0.9800\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.9600\n",
      "Epoch 00076: val_loss improved from 0.10013 to 0.09935, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1342 - accuracy: 0.9600 - val_loss: 0.0994 - val_accuracy: 0.9800\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1334 - accuracy: 0.9600\n",
      "Epoch 00077: val_loss improved from 0.09935 to 0.09850, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1334 - accuracy: 0.9600 - val_loss: 0.0985 - val_accuracy: 0.9800\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1324 - accuracy: 0.9613\n",
      "Epoch 00078: val_loss improved from 0.09850 to 0.09756, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1324 - accuracy: 0.9613 - val_loss: 0.0976 - val_accuracy: 0.9800\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.9625\n",
      "Epoch 00079: val_loss improved from 0.09756 to 0.09668, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1315 - accuracy: 0.9625 - val_loss: 0.0967 - val_accuracy: 0.9800\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1305 - accuracy: 0.9625\n",
      "Epoch 00080: val_loss improved from 0.09668 to 0.09594, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1305 - accuracy: 0.9625 - val_loss: 0.0959 - val_accuracy: 0.9800\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.9625\n",
      "Epoch 00081: val_loss improved from 0.09594 to 0.09531, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1296 - accuracy: 0.9625 - val_loss: 0.0953 - val_accuracy: 0.9800\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.9638\n",
      "Epoch 00082: val_loss improved from 0.09531 to 0.09471, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1288 - accuracy: 0.9638 - val_loss: 0.0947 - val_accuracy: 0.9800\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1279 - accuracy: 0.9638\n",
      "Epoch 00083: val_loss improved from 0.09471 to 0.09410, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1279 - accuracy: 0.9638 - val_loss: 0.0941 - val_accuracy: 0.9800\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1270 - accuracy: 0.9638\n",
      "Epoch 00084: val_loss improved from 0.09410 to 0.09343, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1270 - accuracy: 0.9638 - val_loss: 0.0934 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1262 - accuracy: 0.9650\n",
      "Epoch 00085: val_loss improved from 0.09343 to 0.09268, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.1262 - accuracy: 0.9650 - val_loss: 0.0927 - val_accuracy: 0.9800\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1253 - accuracy: 0.9650\n",
      "Epoch 00086: val_loss improved from 0.09268 to 0.09189, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1253 - accuracy: 0.9650 - val_loss: 0.0919 - val_accuracy: 0.9800\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1245 - accuracy: 0.9638\n",
      "Epoch 00087: val_loss improved from 0.09189 to 0.09110, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.1245 - accuracy: 0.9638 - val_loss: 0.0911 - val_accuracy: 0.9800\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1237 - accuracy: 0.9650\n",
      "Epoch 00088: val_loss improved from 0.09110 to 0.09040, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1237 - accuracy: 0.9650 - val_loss: 0.0904 - val_accuracy: 0.9800\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.9650\n",
      "Epoch 00089: val_loss improved from 0.09040 to 0.08984, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1229 - accuracy: 0.9650 - val_loss: 0.0898 - val_accuracy: 0.9800\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.9663\n",
      "Epoch 00090: val_loss improved from 0.08984 to 0.08943, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1220 - accuracy: 0.9663 - val_loss: 0.0894 - val_accuracy: 0.9800\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.9650\n",
      "Epoch 00091: val_loss improved from 0.08943 to 0.08910, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.1212 - accuracy: 0.9650 - val_loss: 0.0891 - val_accuracy: 0.9800\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1204 - accuracy: 0.9675\n",
      "Epoch 00092: val_loss improved from 0.08910 to 0.08876, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1204 - accuracy: 0.9675 - val_loss: 0.0888 - val_accuracy: 0.9800\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 0.9675\n",
      "Epoch 00093: val_loss improved from 0.08876 to 0.08832, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.1197 - accuracy: 0.9675 - val_loss: 0.0883 - val_accuracy: 0.9800\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.9675\n",
      "Epoch 00094: val_loss improved from 0.08832 to 0.08773, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1189 - accuracy: 0.9675 - val_loss: 0.0877 - val_accuracy: 0.9800\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.9688\n",
      "Epoch 00095: val_loss improved from 0.08773 to 0.08705, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.1182 - accuracy: 0.9688 - val_loss: 0.0870 - val_accuracy: 0.9800\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1174 - accuracy: 0.9725\n",
      "Epoch 00096: val_loss improved from 0.08705 to 0.08634, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1174 - accuracy: 0.9725 - val_loss: 0.0863 - val_accuracy: 0.9800\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1167 - accuracy: 0.9712\n",
      "Epoch 00097: val_loss improved from 0.08634 to 0.08570, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1167 - accuracy: 0.9712 - val_loss: 0.0857 - val_accuracy: 0.9800\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9700\n",
      "Epoch 00098: val_loss improved from 0.08570 to 0.08515, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.1159 - accuracy: 0.9700 - val_loss: 0.0852 - val_accuracy: 0.9800\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9700\n",
      "Epoch 00099: val_loss improved from 0.08515 to 0.08469, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.1152 - accuracy: 0.9700 - val_loss: 0.0847 - val_accuracy: 0.9800\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9712\n",
      "Epoch 00100: val_loss improved from 0.08469 to 0.08429, saving model to models/lr.h5\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.1145 - accuracy: 0.9712 - val_loss: 0.0843 - val_accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(32, 32)),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_x,y_one_hot, epochs=100,batch_size=N,verbose=1,\\\n",
    "          validation_data=(val_x,val_y_one_hot),callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.9712499976158142\n",
      "Validation accuracy:  0.9800000190734863\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# use the model to predict the test inputs\n",
    "predictions = model.predict(test_x)\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "print('Training accuracy: ', acc[-1])\n",
    "print('Validation accuracy: ', val_acc[-1])\n",
    "\n",
    "\n",
    "def index_of_max(output_list):\n",
    "    list_of_indicies = []\n",
    "    for sub_list in output_list:\n",
    "        list_of_indicies.append(np.argmax(sub_list))\n",
    "    return list_of_indicies\n",
    "\n",
    "confusion = tf.math.confusion_matrix(\n",
    "    labels=tf.constant(test_y.flatten()),\n",
    "    predictions=tf.constant(index_of_max(predictions)),\n",
    "    num_classes=2)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(confusion, xticklabels=['0','1'], yticklabels=['0','1'], \n",
    "            annot=True, fmt='g'),\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, val_x, train_y, test_y, val_y, x_mean, x_std = load_dataset()\n",
    "train_x = np.expand_dims(train_x,-1)\n",
    "test_x = np.expand_dims(test_x,-1)\n",
    "val_x = np.expand_dims(val_x,-1)\n",
    "\n",
    "print (train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_74 (Conv2D)           (None, 32, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 1,278,114\n",
      "Trainable params: 1,278,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_train_function.<locals>.train_function at 0x7f5ed422b4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6953 - accuracy: 0.5250WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5ef429def0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61091, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.6953 - accuracy: 0.5250 - val_loss: 0.6109 - val_accuracy: 0.8800\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6062 - accuracy: 0.8938\n",
      "Epoch 00002: val_loss improved from 0.61091 to 0.46932, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6062 - accuracy: 0.8938 - val_loss: 0.4693 - val_accuracy: 0.8800\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4579 - accuracy: 0.8950\n",
      "Epoch 00003: val_loss improved from 0.46932 to 0.37563, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.4579 - accuracy: 0.8950 - val_loss: 0.3756 - val_accuracy: 0.8800\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3531 - accuracy: 0.8988\n",
      "Epoch 00004: val_loss did not improve from 0.37563\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.3531 - accuracy: 0.8988 - val_loss: 0.4248 - val_accuracy: 0.8800\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.9000\n",
      "Epoch 00005: val_loss did not improve from 0.37563\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.3858 - accuracy: 0.9000 - val_loss: 0.4108 - val_accuracy: 0.8800\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3712 - accuracy: 0.9000\n",
      "Epoch 00006: val_loss improved from 0.37563 to 0.36497, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.3712 - accuracy: 0.9000 - val_loss: 0.3650 - val_accuracy: 0.8800\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3388 - accuracy: 0.9000\n",
      "Epoch 00007: val_loss improved from 0.36497 to 0.34578, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.3388 - accuracy: 0.9000 - val_loss: 0.3458 - val_accuracy: 0.8800\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3346 - accuracy: 0.9000\n",
      "Epoch 00008: val_loss improved from 0.34578 to 0.32691, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3346 - accuracy: 0.9000 - val_loss: 0.3269 - val_accuracy: 0.8800\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3115 - accuracy: 0.9000\n",
      "Epoch 00009: val_loss improved from 0.32691 to 0.32423, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3115 - accuracy: 0.9000 - val_loss: 0.3242 - val_accuracy: 0.8800\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3182 - accuracy: 0.9000\n",
      "Epoch 00010: val_loss improved from 0.32423 to 0.31894, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.3182 - accuracy: 0.9000 - val_loss: 0.3189 - val_accuracy: 0.8800\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3172 - accuracy: 0.9013\n",
      "Epoch 00011: val_loss improved from 0.31894 to 0.30635, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.3172 - accuracy: 0.9013 - val_loss: 0.3063 - val_accuracy: 0.8800\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3036 - accuracy: 0.9025\n",
      "Epoch 00012: val_loss improved from 0.30635 to 0.29220, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.3036 - accuracy: 0.9025 - val_loss: 0.2922 - val_accuracy: 0.8800\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2856 - accuracy: 0.9000\n",
      "Epoch 00013: val_loss improved from 0.29220 to 0.27658, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.2856 - accuracy: 0.9000 - val_loss: 0.2766 - val_accuracy: 0.8800\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.9000\n",
      "Epoch 00014: val_loss improved from 0.27658 to 0.25904, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2731 - accuracy: 0.9000 - val_loss: 0.2590 - val_accuracy: 0.8800\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2602 - accuracy: 0.9000\n",
      "Epoch 00015: val_loss improved from 0.25904 to 0.24614, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.2602 - accuracy: 0.9000 - val_loss: 0.2461 - val_accuracy: 0.8900\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 0.9087\n",
      "Epoch 00016: val_loss improved from 0.24614 to 0.22135, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.2588 - accuracy: 0.9087 - val_loss: 0.2213 - val_accuracy: 0.9100\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2337 - accuracy: 0.9125\n",
      "Epoch 00017: val_loss improved from 0.22135 to 0.20069, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.2337 - accuracy: 0.9125 - val_loss: 0.2007 - val_accuracy: 0.9000\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2268 - accuracy: 0.9125\n",
      "Epoch 00018: val_loss improved from 0.20069 to 0.18852, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2268 - accuracy: 0.9125 - val_loss: 0.1885 - val_accuracy: 0.9200\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2144 - accuracy: 0.9150\n",
      "Epoch 00019: val_loss improved from 0.18852 to 0.17161, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.2144 - accuracy: 0.9150 - val_loss: 0.1716 - val_accuracy: 0.9300\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1977 - accuracy: 0.9275\n",
      "Epoch 00020: val_loss improved from 0.17161 to 0.15026, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.1977 - accuracy: 0.9275 - val_loss: 0.1503 - val_accuracy: 0.9400\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1796 - accuracy: 0.9413\n",
      "Epoch 00021: val_loss improved from 0.15026 to 0.14044, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.1796 - accuracy: 0.9413 - val_loss: 0.1404 - val_accuracy: 0.9400\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1650 - accuracy: 0.9375\n",
      "Epoch 00022: val_loss improved from 0.14044 to 0.13098, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.1650 - accuracy: 0.9375 - val_loss: 0.1310 - val_accuracy: 0.9500\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.9500\n",
      "Epoch 00023: val_loss improved from 0.13098 to 0.11705, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.1503 - accuracy: 0.9500 - val_loss: 0.1171 - val_accuracy: 0.9400\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1447 - accuracy: 0.9513\n",
      "Epoch 00024: val_loss improved from 0.11705 to 0.10418, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.1447 - accuracy: 0.9513 - val_loss: 0.1042 - val_accuracy: 0.9500\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.9588\n",
      "Epoch 00025: val_loss improved from 0.10418 to 0.10304, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1284 - accuracy: 0.9588 - val_loss: 0.1030 - val_accuracy: 0.9600\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.9538\n",
      "Epoch 00026: val_loss improved from 0.10304 to 0.09334, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.1148 - accuracy: 0.9538 - val_loss: 0.0933 - val_accuracy: 0.9500\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9638\n",
      "Epoch 00027: val_loss improved from 0.09334 to 0.06974, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1003 - accuracy: 0.9638 - val_loss: 0.0697 - val_accuracy: 0.9800\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9775\n",
      "Epoch 00028: val_loss did not improve from 0.06974\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0940 - accuracy: 0.9775 - val_loss: 0.0732 - val_accuracy: 0.9700\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1020 - accuracy: 0.9737\n",
      "Epoch 00029: val_loss improved from 0.06974 to 0.05668, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.1020 - accuracy: 0.9737 - val_loss: 0.0567 - val_accuracy: 0.9800\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9787\n",
      "Epoch 00030: val_loss improved from 0.05668 to 0.05151, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0779 - accuracy: 0.9787 - val_loss: 0.0515 - val_accuracy: 0.9900\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9750\n",
      "Epoch 00031: val_loss did not improve from 0.05151\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0841 - accuracy: 0.9750 - val_loss: 0.0685 - val_accuracy: 0.9800\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9737\n",
      "Epoch 00032: val_loss improved from 0.05151 to 0.04626, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0847 - accuracy: 0.9737 - val_loss: 0.0463 - val_accuracy: 0.9900\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9825\n",
      "Epoch 00033: val_loss improved from 0.04626 to 0.04364, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.0588 - accuracy: 0.9825 - val_loss: 0.0436 - val_accuracy: 0.9800\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9762\n",
      "Epoch 00034: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0765 - accuracy: 0.9762 - val_loss: 0.0572 - val_accuracy: 0.9800\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9925\n",
      "Epoch 00035: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0552 - accuracy: 0.9925 - val_loss: 0.0728 - val_accuracy: 0.9800\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.9850\n",
      "Epoch 00036: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0610 - accuracy: 0.9850 - val_loss: 0.0608 - val_accuracy: 0.9900\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9950\n",
      "Epoch 00037: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0460 - accuracy: 0.9950 - val_loss: 0.0524 - val_accuracy: 0.9900\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9937\n",
      "Epoch 00038: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0473 - accuracy: 0.9937 - val_loss: 0.0547 - val_accuracy: 0.9900\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9900\n",
      "Epoch 00039: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0501 - accuracy: 0.9900 - val_loss: 0.0562 - val_accuracy: 0.9900\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9887\n",
      "Epoch 00040: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0476 - accuracy: 0.9887 - val_loss: 0.0640 - val_accuracy: 0.9900\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9912\n",
      "Epoch 00041: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0457 - accuracy: 0.9912 - val_loss: 0.0653 - val_accuracy: 0.9900\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9925\n",
      "Epoch 00042: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0406 - accuracy: 0.9925 - val_loss: 0.0581 - val_accuracy: 0.9900\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9925\n",
      "Epoch 00043: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0377 - accuracy: 0.9925 - val_loss: 0.0550 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9937\n",
      "Epoch 00044: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0327 - accuracy: 0.9937 - val_loss: 0.0565 - val_accuracy: 0.9900\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9937\n",
      "Epoch 00045: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0376 - accuracy: 0.9937 - val_loss: 0.0614 - val_accuracy: 0.9900\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9925\n",
      "Epoch 00046: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0324 - accuracy: 0.9925 - val_loss: 0.0641 - val_accuracy: 0.9900\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9950\n",
      "Epoch 00047: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0312 - accuracy: 0.9950 - val_loss: 0.0635 - val_accuracy: 0.9900\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9962\n",
      "Epoch 00048: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0309 - accuracy: 0.9962 - val_loss: 0.0636 - val_accuracy: 0.9900\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9962\n",
      "Epoch 00049: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0275 - accuracy: 0.9962 - val_loss: 0.0633 - val_accuracy: 0.9900\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9962\n",
      "Epoch 00050: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0269 - accuracy: 0.9962 - val_loss: 0.0628 - val_accuracy: 0.9900\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9950\n",
      "Epoch 00051: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0312 - accuracy: 0.9950 - val_loss: 0.0616 - val_accuracy: 0.9900\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9962\n",
      "Epoch 00052: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0240 - accuracy: 0.9962 - val_loss: 0.0603 - val_accuracy: 0.9900\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9962\n",
      "Epoch 00053: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0236 - accuracy: 0.9962 - val_loss: 0.0611 - val_accuracy: 0.9900\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9950\n",
      "Epoch 00054: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0268 - accuracy: 0.9950 - val_loss: 0.0624 - val_accuracy: 0.9900\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9962\n",
      "Epoch 00055: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0225 - accuracy: 0.9962 - val_loss: 0.0663 - val_accuracy: 0.9900\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9937\n",
      "Epoch 00056: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0243 - accuracy: 0.9937 - val_loss: 0.0702 - val_accuracy: 0.9900\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9937\n",
      "Epoch 00057: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0215 - accuracy: 0.9937 - val_loss: 0.0689 - val_accuracy: 0.9900\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9937\n",
      "Epoch 00058: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 0.0731 - val_accuracy: 0.9900\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9937\n",
      "Epoch 00059: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0234 - accuracy: 0.9937 - val_loss: 0.0711 - val_accuracy: 0.9900\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9950\n",
      "Epoch 00060: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.0210 - accuracy: 0.9950 - val_loss: 0.0673 - val_accuracy: 0.9900\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9950\n",
      "Epoch 00061: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0177 - accuracy: 0.9950 - val_loss: 0.0616 - val_accuracy: 0.9900\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9962\n",
      "Epoch 00062: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.0612 - val_accuracy: 0.9900\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9950\n",
      "Epoch 00063: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0170 - accuracy: 0.9950 - val_loss: 0.0587 - val_accuracy: 0.9900\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9950\n",
      "Epoch 00064: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 0.0530 - val_accuracy: 0.9900\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9925\n",
      "Epoch 00065: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0170 - accuracy: 0.9925 - val_loss: 0.0528 - val_accuracy: 0.9900\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9987\n",
      "Epoch 00066: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0094 - accuracy: 0.9987 - val_loss: 0.0541 - val_accuracy: 0.9900\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9962\n",
      "Epoch 00067: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0094 - accuracy: 0.9962 - val_loss: 0.0533 - val_accuracy: 0.9900\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9962\n",
      "Epoch 00068: val_loss did not improve from 0.04364\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.0503 - val_accuracy: 0.9900\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9975\n",
      "Epoch 00069: val_loss improved from 0.04364 to 0.03235, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.0324 - val_accuracy: 0.9900\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9975\n",
      "Epoch 00070: val_loss improved from 0.03235 to 0.01944, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0064 - accuracy: 0.9975 - val_loss: 0.0194 - val_accuracy: 0.9900\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9950\n",
      "Epoch 00071: val_loss did not improve from 0.01944\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0101 - accuracy: 0.9950 - val_loss: 0.0312 - val_accuracy: 0.9900\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9962\n",
      "Epoch 00072: val_loss did not improve from 0.01944\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0100 - accuracy: 0.9962 - val_loss: 0.0539 - val_accuracy: 0.9900\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9975\n",
      "Epoch 00073: val_loss did not improve from 0.01944\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.0486 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9962\n",
      "Epoch 00074: val_loss did not improve from 0.01944\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0092 - accuracy: 0.9962 - val_loss: 0.0211 - val_accuracy: 0.9900\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9987\n",
      "Epoch 00075: val_loss improved from 0.01944 to 0.00596, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9975\n",
      "Epoch 00076: val_loss improved from 0.00596 to 0.00467, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0056 - accuracy: 0.9975 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9962\n",
      "Epoch 00077: val_loss did not improve from 0.00467\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.0144 - val_accuracy: 0.9900\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9962\n",
      "Epoch 00078: val_loss did not improve from 0.00467\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0054 - accuracy: 0.9962 - val_loss: 0.0386 - val_accuracy: 0.9900\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 00079: val_loss did not improve from 0.00467\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0396 - val_accuracy: 0.9900\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9950\n",
      "Epoch 00080: val_loss did not improve from 0.00467\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.0093 - accuracy: 0.9950 - val_loss: 0.0165 - val_accuracy: 0.9900\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 00081: val_loss did not improve from 0.00467\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9987\n",
      "Epoch 00082: val_loss improved from 0.00467 to 0.00331, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9975\n",
      "Epoch 00083: val_loss did not improve from 0.00331\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.0085 - val_accuracy: 0.9900\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9987\n",
      "Epoch 00084: val_loss did not improve from 0.00331\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.0176 - val_accuracy: 0.9900\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 00085: val_loss did not improve from 0.00331\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9900\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9975\n",
      "Epoch 00086: val_loss did not improve from 0.00331\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 00087: val_loss improved from 0.00331 to 0.00101, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 00088: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 00089: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9987\n",
      "Epoch 00090: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9975\n",
      "Epoch 00091: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.0176 - val_accuracy: 0.9900\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 00092: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9900\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9975\n",
      "Epoch 00093: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0060 - accuracy: 0.9975 - val_loss: 0.0219 - val_accuracy: 0.9900\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9987\n",
      "Epoch 00094: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 0.0119 - val_accuracy: 0.9900\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 00095: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.9481e-04 - accuracy: 1.0000\n",
      "Epoch 00096: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 7.9481e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 00097: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 00098: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 00099: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0093 - val_accuracy: 0.9900\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.6386e-04 - accuracy: 1.0000\n",
      "Epoch 00100: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 9.6386e-04 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9900\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9987\n",
      "Epoch 00101: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0013 - accuracy: 0.9987 - val_loss: 0.0281 - val_accuracy: 0.9900\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.9245e-04 - accuracy: 1.0000\n",
      "Epoch 00102: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 4.9245e-04 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9900\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9937\n",
      "Epoch 00103: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0141 - accuracy: 0.9937 - val_loss: 0.0264 - val_accuracy: 0.9900\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9987\n",
      "Epoch 00104: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0016 - accuracy: 0.9987 - val_loss: 0.0287 - val_accuracy: 0.9900\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9975\n",
      "Epoch 00105: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0034 - accuracy: 0.9975 - val_loss: 0.0471 - val_accuracy: 0.9800\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9950\n",
      "Epoch 00106: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0117 - accuracy: 0.9950 - val_loss: 0.0147 - val_accuracy: 0.9900\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.7674e-04 - accuracy: 1.0000\n",
      "Epoch 00107: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 8.7674e-04 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9900\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9987\n",
      "Epoch 00108: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 0.0186 - val_accuracy: 0.9900\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9950\n",
      "Epoch 00109: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0127 - accuracy: 0.9950 - val_loss: 0.0351 - val_accuracy: 0.9900\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 00110: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9900\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9975\n",
      "Epoch 00111: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0044 - accuracy: 0.9975 - val_loss: 0.0848 - val_accuracy: 0.9900\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9987\n",
      "Epoch 00112: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 0.1027 - val_accuracy: 0.9900\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9962\n",
      "Epoch 00113: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.0786 - val_accuracy: 0.9900\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.8191e-04 - accuracy: 1.0000\n",
      "Epoch 00114: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 7.8191e-04 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9900\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9987\n",
      "Epoch 00115: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 0.0297 - val_accuracy: 0.9900\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9987\n",
      "Epoch 00116: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.0240 - val_accuracy: 0.9900\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.5558e-04 - accuracy: 1.0000\n",
      "Epoch 00117: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 7.5558e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9900\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.4837e-04 - accuracy: 1.0000\n",
      "Epoch 00118: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 8.4837e-04 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9900\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 00119: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9900\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7161e-04 - accuracy: 1.0000\n",
      "Epoch 00120: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.7161e-04 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9900\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1497e-04 - accuracy: 1.0000\n",
      "Epoch 00121: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.1497e-04 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9900\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9987\n",
      "Epoch 00122: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0013 - accuracy: 0.9987 - val_loss: 0.0415 - val_accuracy: 0.9900\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1018e-04 - accuracy: 1.0000\n",
      "Epoch 00123: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 5.1018e-04 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9900\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.2870e-04 - accuracy: 1.0000\n",
      "Epoch 00124: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 4.2870e-04 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9900\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9987\n",
      "Epoch 00125: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0012 - accuracy: 0.9987 - val_loss: 0.0344 - val_accuracy: 0.9900\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9975\n",
      "Epoch 00126: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0054 - accuracy: 0.9975 - val_loss: 0.0400 - val_accuracy: 0.9900\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.9947e-04 - accuracy: 1.0000\n",
      "Epoch 00127: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 6.9947e-04 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9900\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.5121e-04 - accuracy: 1.0000\n",
      "Epoch 00128: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.5121e-04 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9900\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.3070e-04 - accuracy: 1.0000\n",
      "Epoch 00129: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 6.3070e-04 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9900\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.6492e-04 - accuracy: 1.0000\n",
      "Epoch 00130: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 3.6492e-04 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9900\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9987\n",
      "Epoch 00131: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 0.0300 - val_accuracy: 0.9900\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4026e-04 - accuracy: 1.0000\n",
      "Epoch 00132: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 2.4026e-04 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2860e-04 - accuracy: 1.0000\n",
      "Epoch 00133: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 1.2860e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.5675e-04 - accuracy: 1.0000\n",
      "Epoch 00134: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 2.5675e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6576e-04 - accuracy: 1.0000\n",
      "Epoch 00135: val_loss improved from 0.00101 to 0.00031, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 1.6576e-04 - accuracy: 1.0000 - val_loss: 3.0592e-04 - val_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1666e-04 - accuracy: 1.0000\n",
      "Epoch 00136: val_loss improved from 0.00031 to 0.00012, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 2.1666e-04 - accuracy: 1.0000 - val_loss: 1.1941e-04 - val_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 00137: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 1.6035e-04 - val_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9987\n",
      "Epoch 00138: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 5.4940e-04 - val_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0860e-04 - accuracy: 1.0000\n",
      "Epoch 00139: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.0860e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3760e-04 - accuracy: 1.0000\n",
      "Epoch 00140: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.3760e-04 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.3376e-05 - accuracy: 1.0000\n",
      "Epoch 00141: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 7.3376e-05 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9900\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5339e-04 - accuracy: 1.0000\n",
      "Epoch 00142: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.5339e-04 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9900\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2227e-04 - accuracy: 1.0000\n",
      "Epoch 00143: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 3.2227e-04 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9900\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5379e-04 - accuracy: 1.0000\n",
      "Epoch 00144: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 1.5379e-04 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9900\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.5633e-04 - accuracy: 1.0000\n",
      "Epoch 00145: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 8.5633e-04 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9900\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9987\n",
      "Epoch 00146: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 0.0184 - val_accuracy: 0.9900\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4504e-04 - accuracy: 1.0000\n",
      "Epoch 00147: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.4504e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.8670e-04 - accuracy: 1.0000\n",
      "Epoch 00148: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 4.8670e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0778e-04 - accuracy: 1.0000\n",
      "Epoch 00149: val_loss did not improve from 0.00012\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 3.0778e-04 - accuracy: 1.0000 - val_loss: 2.9025e-04 - val_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4671e-04 - accuracy: 1.0000\n",
      "Epoch 00150: val_loss improved from 0.00012 to 0.00011, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 2.4671e-04 - accuracy: 1.0000 - val_loss: 1.0836e-04 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9987\n",
      "Epoch 00151: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.6290e-04 - val_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2695e-04 - accuracy: 1.0000\n",
      "Epoch 00152: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 1.2695e-04 - accuracy: 1.0000 - val_loss: 2.4230e-04 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.1505e-05 - accuracy: 1.0000\n",
      "Epoch 00153: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 4.1505e-05 - accuracy: 1.0000 - val_loss: 3.4840e-04 - val_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.2961e-05 - accuracy: 1.0000\n",
      "Epoch 00154: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 6.2961e-05 - accuracy: 1.0000 - val_loss: 4.8553e-04 - val_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1272e-04 - accuracy: 1.0000\n",
      "Epoch 00155: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 1.1272e-04 - accuracy: 1.0000 - val_loss: 6.5851e-04 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.6191e-05 - accuracy: 1.0000\n",
      "Epoch 00156: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 9.6191e-05 - accuracy: 1.0000 - val_loss: 8.1215e-04 - val_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9679e-04 - accuracy: 1.0000\n",
      "Epoch 00157: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 2.9679e-04 - accuracy: 1.0000 - val_loss: 8.3871e-04 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.6160e-04 - accuracy: 1.0000\n",
      "Epoch 00158: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 6.6160e-04 - accuracy: 1.0000 - val_loss: 6.1170e-04 - val_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.2183e-05 - accuracy: 1.0000\n",
      "Epoch 00159: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 6.2183e-05 - accuracy: 1.0000 - val_loss: 4.3804e-04 - val_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.7012e-04 - accuracy: 1.0000\n",
      "Epoch 00160: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 5.7012e-04 - accuracy: 1.0000 - val_loss: 2.9503e-04 - val_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.2479e-05 - accuracy: 1.0000\n",
      "Epoch 00161: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 5.2479e-05 - accuracy: 1.0000 - val_loss: 2.0204e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2906e-05 - accuracy: 1.0000\n",
      "Epoch 00162: val_loss did not improve from 0.00011\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 9.2906e-05 - accuracy: 1.0000 - val_loss: 1.4143e-04 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.3648e-05 - accuracy: 1.0000\n",
      "Epoch 00163: val_loss improved from 0.00011 to 0.00010, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 4.3648e-05 - accuracy: 1.0000 - val_loss: 1.0448e-04 - val_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.8413e-05 - accuracy: 1.0000\n",
      "Epoch 00164: val_loss improved from 0.00010 to 0.00008, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 9.8413e-05 - accuracy: 1.0000 - val_loss: 7.7500e-05 - val_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0662e-04 - accuracy: 1.0000\n",
      "Epoch 00165: val_loss improved from 0.00008 to 0.00006, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 1.0662e-04 - accuracy: 1.0000 - val_loss: 5.5432e-05 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.2414e-05 - accuracy: 1.0000\n",
      "Epoch 00166: val_loss improved from 0.00006 to 0.00004, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 8.2414e-05 - accuracy: 1.0000 - val_loss: 4.2203e-05 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.3880e-05 - accuracy: 1.0000\n",
      "Epoch 00167: val_loss improved from 0.00004 to 0.00003, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 4.3880e-05 - accuracy: 1.0000 - val_loss: 3.3134e-05 - val_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3865e-05 - accuracy: 1.0000\n",
      "Epoch 00168: val_loss improved from 0.00003 to 0.00003, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 2.3865e-05 - accuracy: 1.0000 - val_loss: 2.6960e-05 - val_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7759e-05 - accuracy: 1.0000\n",
      "Epoch 00169: val_loss improved from 0.00003 to 0.00002, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 1.7759e-05 - accuracy: 1.0000 - val_loss: 2.2762e-05 - val_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1456e-05 - accuracy: 1.0000\n",
      "Epoch 00170: val_loss improved from 0.00002 to 0.00002, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 5.1456e-05 - accuracy: 1.0000 - val_loss: 1.9711e-05 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9315e-05 - accuracy: 1.0000\n",
      "Epoch 00171: val_loss improved from 0.00002 to 0.00002, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 2.9315e-05 - accuracy: 1.0000 - val_loss: 1.7698e-05 - val_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.8223e-05 - accuracy: 1.0000\n",
      "Epoch 00172: val_loss improved from 0.00002 to 0.00002, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 3.8223e-05 - accuracy: 1.0000 - val_loss: 1.6165e-05 - val_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2625e-04 - accuracy: 1.0000\n",
      "Epoch 00173: val_loss improved from 0.00002 to 0.00002, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 1.2625e-04 - accuracy: 1.0000 - val_loss: 1.5827e-05 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.0989e-04 - accuracy: 1.0000\n",
      "Epoch 00174: val_loss did not improve from 0.00002\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 5.0989e-04 - accuracy: 1.0000 - val_loss: 1.9255e-05 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.3357e-05 - accuracy: 1.0000\n",
      "Epoch 00175: val_loss did not improve from 0.00002\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 9.3357e-05 - accuracy: 1.0000 - val_loss: 2.1886e-05 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.7719e-04 - accuracy: 1.0000\n",
      "Epoch 00176: val_loss did not improve from 0.00002\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.7719e-04 - accuracy: 1.0000 - val_loss: 3.1843e-05 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.8113e-05 - accuracy: 1.0000\n",
      "Epoch 00177: val_loss did not improve from 0.00002\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 6.8113e-05 - accuracy: 1.0000 - val_loss: 4.7285e-05 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9987\n",
      "Epoch 00178: val_loss did not improve from 0.00002\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0017 - accuracy: 0.9987 - val_loss: 2.1958e-05 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.6264e-04 - accuracy: 1.0000\n",
      "Epoch 00179: val_loss improved from 0.00002 to 0.00001, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 2.6264e-04 - accuracy: 1.0000 - val_loss: 1.2641e-05 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.0369e-05 - accuracy: 1.0000\n",
      "Epoch 00180: val_loss improved from 0.00001 to 0.00001, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 9.0369e-05 - accuracy: 1.0000 - val_loss: 9.2833e-06 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4922e-04 - accuracy: 1.0000\n",
      "Epoch 00181: val_loss improved from 0.00001 to 0.00001, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 1.4922e-04 - accuracy: 1.0000 - val_loss: 7.9697e-06 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.1428e-05 - accuracy: 1.0000\n",
      "Epoch 00182: val_loss improved from 0.00001 to 0.00001, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 9.1428e-05 - accuracy: 1.0000 - val_loss: 7.2940e-06 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9987\n",
      "Epoch 00183: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 7.8562e-06 - val_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9987\n",
      "Epoch 00184: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 3.8672e-05 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0451e-04 - accuracy: 1.0000\n",
      "Epoch 00185: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 3.0451e-04 - accuracy: 1.0000 - val_loss: 4.4004e-04 - val_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.8667e-05 - accuracy: 1.0000\n",
      "Epoch 00186: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 6.8667e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9987\n",
      "Epoch 00187: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 0.0070 - val_accuracy: 0.9900\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.6005e-04 - accuracy: 1.0000\n",
      "Epoch 00188: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 5.6005e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.3892e-04 - accuracy: 1.0000\n",
      "Epoch 00189: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 8.3892e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.5200e-04 - accuracy: 1.0000\n",
      "Epoch 00190: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 3.5200e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2432e-04 - accuracy: 1.0000\n",
      "Epoch 00191: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 2.2432e-04 - accuracy: 1.0000 - val_loss: 5.0212e-04 - val_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.6237e-04 - accuracy: 1.0000\n",
      "Epoch 00192: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 5.6237e-04 - accuracy: 1.0000 - val_loss: 1.5275e-04 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.0127e-05 - accuracy: 1.0000\n",
      "Epoch 00193: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 6.0127e-05 - accuracy: 1.0000 - val_loss: 5.1675e-05 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.2577e-05 - accuracy: 1.0000\n",
      "Epoch 00194: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 5.2577e-05 - accuracy: 1.0000 - val_loss: 2.0506e-05 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.6759e-05 - accuracy: 1.0000\n",
      "Epoch 00195: val_loss did not improve from 0.00001\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 2.6759e-05 - accuracy: 1.0000 - val_loss: 9.7590e-06 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.4126e-04 - accuracy: 1.0000\n",
      "Epoch 00196: val_loss improved from 0.00001 to 0.00000, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 8.4126e-04 - accuracy: 1.0000 - val_loss: 3.2687e-06 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.3828e-05 - accuracy: 1.0000\n",
      "Epoch 00197: val_loss improved from 0.00000 to 0.00000, saving model to models/cnn.h5\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 4.3828e-05 - accuracy: 1.0000 - val_loss: 2.6667e-06 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.0998e-04 - accuracy: 1.0000\n",
      "Epoch 00198: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 4.0998e-04 - accuracy: 1.0000 - val_loss: 3.1926e-06 - val_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9975\n",
      "Epoch 00199: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0056 - accuracy: 0.9975 - val_loss: 3.3736e-06 - val_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.4635e-05 - accuracy: 1.0000\n",
      "Epoch 00200: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 9.4635e-05 - accuracy: 1.0000 - val_loss: 1.0620e-05 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.9156e-04 - accuracy: 1.0000\n",
      "Epoch 00201: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 5.9156e-04 - accuracy: 1.0000 - val_loss: 4.7464e-05 - val_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2018e-04 - accuracy: 1.0000\n",
      "Epoch 00202: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 2.2018e-04 - accuracy: 1.0000 - val_loss: 2.4137e-04 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.7124e-04 - accuracy: 1.0000\n",
      "Epoch 00203: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 4.7124e-04 - accuracy: 1.0000 - val_loss: 7.8133e-04 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0495e-04 - accuracy: 1.0000\n",
      "Epoch 00204: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.0495e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9987\n",
      "Epoch 00205: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.7553e-04 - accuracy: 1.0000\n",
      "Epoch 00206: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 9.7553e-04 - accuracy: 1.0000 - val_loss: 1.8936e-04 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.5906e-05 - accuracy: 1.0000\n",
      "Epoch 00207: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 8.5906e-05 - accuracy: 1.0000 - val_loss: 4.0188e-05 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.6360e-05 - accuracy: 1.0000\n",
      "Epoch 00208: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 8.6360e-05 - accuracy: 1.0000 - val_loss: 1.2205e-05 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.6022e-05 - accuracy: 1.0000\n",
      "Epoch 00209: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2.6022e-05 - accuracy: 1.0000 - val_loss: 5.7978e-06 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7276e-05 - accuracy: 1.0000\n",
      "Epoch 00210: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.7276e-05 - accuracy: 1.0000 - val_loss: 3.8640e-06 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.7088e-04 - accuracy: 1.0000\n",
      "Epoch 00211: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 4.7088e-04 - accuracy: 1.0000 - val_loss: 3.0248e-06 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9987\n",
      "Epoch 00212: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 3.0961e-06 - val_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.9864e-04 - accuracy: 1.0000\n",
      "Epoch 00213: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 8.9864e-04 - accuracy: 1.0000 - val_loss: 7.5662e-06 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2190e-05 - accuracy: 1.0000\n",
      "Epoch 00214: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.2190e-05 - accuracy: 1.0000 - val_loss: 3.6567e-05 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.3390e-04 - accuracy: 1.0000\n",
      "Epoch 00215: val_loss did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 8.3390e-04 - accuracy: 1.0000 - val_loss: 4.3320e-04 - val_accuracy: 1.0000\n",
      "Epoch 216/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-5600db0e85ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     23\u001b[0m model.fit(train_x,y_one_hot, epochs=500,batch_size=N,verbose=1,\n\u001b[0;32m---> 24\u001b[0;31m           validation_data=(val_x,val_y_one_hot),callbacks=[checkpoint])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate= 0.001)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('models/cnn.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "# build the model and train it\n",
    "model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, (3, 3),padding='same',activation=\"relu\",input_shape=(32, 32,1)),\n",
    "      tf.keras.layers.Conv2D(32, (3, 3),activation=\"relu\",input_shape=(32, 32,32)),  \n",
    "      tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2), padding='valid'),\n",
    "      tf.keras.layers.Dropout(0.25),\n",
    "      tf.keras.layers.Conv2D(64, (3, 3),padding='same',activation=\"relu\",input_shape=(15, 15,32)),  \n",
    "      tf.keras.layers.Conv2D(64, (3, 3),activation=\"relu\",input_shape=(15, 15,64)),  \n",
    "      tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2), padding='valid'),\n",
    "      tf.keras.layers.Dropout(0.25),\n",
    "      tf.keras.layers.Flatten(),  \n",
    "      tf.keras.layers.Dense(512, activation=\"relu\")  ,\n",
    "      tf.keras.layers.Dropout(0.5),\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(2)  \n",
    "])\n",
    "model.summary()\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_x,y_one_hot, epochs=500,batch_size=N,verbose=1,\n",
    "          validation_data=(val_x,val_y_one_hot),callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.9712499976158142\n",
      "Validation accuracy:  0.9800000190734863\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(test_x)\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "print('Training accuracy: ', acc[-1])\n",
    "print('Validation accuracy: ', val_acc[-1])\n",
    "\n",
    "confusion = tf.math.confusion_matrix(\n",
    "    labels=tf.constant(test_y.flatten()),\n",
    "    predictions=tf.constant(index_of_max(predictions)),\n",
    "    num_classes=2)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(confusion, xticklabels=['0','1'], yticklabels=['0','1'], \n",
    "            annot=True, fmt='g'),\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
